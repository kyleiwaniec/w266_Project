{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# The RNN implementation\n",
    "import processing\n",
    "import rnnlm\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from features import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(corpus, training_data, model_name, model_params, max_time, batch_size,\n",
    "                learning_rate, keep_prob, num_epochs):    \n",
    "    trained_filename = 'tf_saved/rnnlm_%s' % model_name\n",
    "    \n",
    "    # Will print status every this many seconds\n",
    "    print_interval = 5\n",
    "\n",
    "    # Clear old log directory\n",
    "    shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        # Seed RNG for repeatability\n",
    "        tf.set_random_seed(42)\n",
    "  \n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = rnnlm.RNNLM(model_params)\n",
    "            lm.BuildCoreGraph()\n",
    "            lm.BuildTrainGraph()\n",
    "  \n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "  \n",
    "        for epoch in xrange(1,num_epochs+1):\n",
    "            t0_epoch = time.time()\n",
    "            bi = processing.batch_generator(training_data[\"train_ids\"], batch_size, max_time)\n",
    "            print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "\n",
    "            # Run a training epoch.\n",
    "            lm.RunEpoch(session, bi, train=True, verbose=True, keep_prob=keep_prob)\n",
    "\n",
    "            print \"[epoch %d] Completed in %s\" % (epoch, rnnlm.pretty_timedelta(since=t0_epoch))\n",
    "\n",
    "            print (\"[epoch %d]\" % epoch),\n",
    "            lm.ScoreDataset(session, training_data[\"test_ids\"], name=\"Test set\")\n",
    "            print \"\"\n",
    "\n",
    "            # Save a checkpoint\n",
    "            saver.save(session, 'tf_saved/rnnlm', global_step=epoch)\n",
    "    \n",
    "        # Save final model\n",
    "        saver.save(session, trained_filename)\n",
    "        \n",
    "    print \"Done training.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "class RNNClassifierFeatureExtractor(object):\n",
    "    def __init__(self, corpus, model_params, true_model, false_model):\n",
    "        self.corpus = corpus\n",
    "        self.model_params = model_params\n",
    "        self.true_model = true_model\n",
    "        self.false_model = false_model\n",
    "        \n",
    "    def score_sentences(self, inputs, trained_filename):\n",
    "        with tf.Graph().as_default(), tf.Session() as session:\n",
    "            with tf.variable_scope(\"model\", reuse=None):\n",
    "                lm = rnnlm.RNNLM(self.model_params)\n",
    "                lm.BuildCoreGraph()\n",
    "\n",
    "            # Load the trained model\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(session, trained_filename)\n",
    "\n",
    "            # Actually run scoring\n",
    "            results = []\n",
    "            for idx, s in enumerate(inputs):\n",
    "                score = 0\n",
    "                for sent in processing.tokenize_sentences(s):\n",
    "                    score -= lm.ScoreSeq(session, sent, self.corpus.vocab)\n",
    "                results.append(score)\n",
    "                if idx % 100 == 0:\n",
    "                    print \"  %d / %d (%f)\" % (idx, len(inputs), score)\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def train(self, train_data):\n",
    "        return self.transform(train_data)\n",
    "        \n",
    "    def transform(self, test_data):\n",
    "        print \"True scores...\"\n",
    "        true_scores = self.score_sentences(test_data[\"content\"], \"tf_saved/rnnlm_%s\" % self.true_model)\n",
    "        print \"False scores...\"\n",
    "        false_scores = self.score_sentences(test_data[\"content\"], \"tf_saved/rnnlm_%s\" % self.false_model)\n",
    "        return scipy.sparse.csr_matrix([[x, y] for x, y in zip(true_scores, false_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hasVotes-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print \"Loading dataset...\"\n",
    "with open(\"/usr/src/app/data/ka-comments-balanced.pickle\", \"rb\") as f:\n",
    "    comments_dataset = pickle.load(f)    \n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "model_params = rnnlm.RNNParams(V=100000, H=250, num_layers=2)\n",
    "train_params = {\n",
    "    \"max_time\": 20,\n",
    "    \"batch_size\": 50,\n",
    "    \"learning_rate\": 0.0025,\n",
    "    \"keep_prob\": 0.5,\n",
    "    \"num_epochs\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "corpus = processing.Corpus(comments_dataset[\"train_data\"][\"content\"], model_params.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "mini_training_data = corpus.generate_training_data(\n",
    "    comments_dataset[\"train_data\"].iloc[:5000][\"content\"],\n",
    "    train_frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(corpus, mini_training_data, \"test\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "true_training_data = corpus.generate_training_data(\n",
    "    comments_dataset[\"train_data\"][comments_dataset[\"train_data\"][\"hasVotes\"] == True][\"content\"],\n",
    "    train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(corpus, true_training_data, \"true_all\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "false_training_data = corpus.generate_training_data(\n",
    "    comments_dataset[\"train_data\"][comments_dataset[\"train_data\"][\"hasVotes\"] == False][\"content\"],\n",
    "    train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(corpus, false_training_data, \"false_all\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "sents = [\"the quick brown fox jumps over the lazy dog\",\n",
    "         \"the fox quick brown jumps over the lazy dog\",\n",
    "        \"the fox quick brown jumps dog over the lazy\"]\n",
    "print \"Scores for TRUE model:\"\n",
    "rnnlm.load_and_score([s.split() for s in sents], corpus, model_params, \"tf_saved/rnnlm_true_all\")\n",
    "print \"Scores for FALSE model:\"\n",
    "rnnlm.load_and_score([s.split() for s in sents], corpus, model_params, \"tf_saved/rnnlm_false_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "reload(common)\n",
    "common.extract_features(\n",
    "    \"ka-comments-balanced\",\n",
    "    RNNClassifierFeatureExtractor(corpus, model_params, \"true_all\", \"false_all\"),\n",
    "    \"all-rnn\", sampling=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features all-rnn.\n",
      "Training models.\n",
      "##        MultinomialNB         all-rnn precision: 62.9% recall: 62.9%\n",
      "##            LinearSVC         all-rnn precision: 55.4% recall: 93.2%\n",
      "##                  MLP         all-rnn precision: 65.1% recall: 60.1%\n",
      "##                 MLP2         all-rnn precision: 66.9% recall: 53.8%\n"
     ]
    }
   ],
   "source": [
    "reload(common)\n",
    "common.test_features(\"all-rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ka-replies-balanced dataset.\n",
      "Training feature extractor reply-rnn.\n",
      "True scores...\n",
      "  0 / 7705 (201.533875)\n",
      "  100 / 7705 (69.320618)\n",
      "  200 / 7705 (232.644455)\n",
      "  300 / 7705 (1046.712555)\n",
      "  400 / 7705 (914.276390)\n",
      "  500 / 7705 (1117.368958)\n",
      "  600 / 7705 (149.922226)\n",
      "  700 / 7705 (324.027397)\n",
      "  800 / 7705 (192.422653)\n",
      "  900 / 7705 (339.794617)\n",
      "  1000 / 7705 (379.480927)\n",
      "  1100 / 7705 (658.827087)\n",
      "  1200 / 7705 (230.566313)\n",
      "  1300 / 7705 (207.059769)\n",
      "  1400 / 7705 (472.427658)\n",
      "  1500 / 7705 (60.874001)\n",
      "  1600 / 7705 (514.879982)\n",
      "  1700 / 7705 (392.418266)\n",
      "  1800 / 7705 (471.909561)\n",
      "  1900 / 7705 (273.428284)\n",
      "  2000 / 7705 (450.746002)\n",
      "  2100 / 7705 (660.454025)\n",
      "  2200 / 7705 (120.546432)\n",
      "  2300 / 7705 (911.398396)\n",
      "  2400 / 7705 (84.223907)\n",
      "  2500 / 7705 (141.128983)\n",
      "  2600 / 7705 (380.456436)\n",
      "  2700 / 7705 (296.025970)\n",
      "  2800 / 7705 (427.473694)\n",
      "  2900 / 7705 (323.535736)\n",
      "  3000 / 7705 (228.716812)\n",
      "  3100 / 7705 (127.822060)\n",
      "  3200 / 7705 (137.855209)\n",
      "  3300 / 7705 (888.512474)\n",
      "  3400 / 7705 (818.332336)\n",
      "  3500 / 7705 (59.129787)\n",
      "  3600 / 7705 (812.012075)\n",
      "  3700 / 7705 (60.098064)\n",
      "  3800 / 7705 (453.369286)\n",
      "  3900 / 7705 (95.193085)\n",
      "  4000 / 7705 (79.151466)\n",
      "  4100 / 7705 (127.565582)\n",
      "  4200 / 7705 (286.162426)\n",
      "  4300 / 7705 (124.694160)\n",
      "  4400 / 7705 (142.685013)\n",
      "  4500 / 7705 (618.551514)\n",
      "  4600 / 7705 (65.796303)\n",
      "  4700 / 7705 (158.977032)\n",
      "  4800 / 7705 (492.001915)\n",
      "  4900 / 7705 (41.854134)\n",
      "  5000 / 7705 (94.461235)\n",
      "  5100 / 7705 (552.937008)\n",
      "  5200 / 7705 (122.173904)\n",
      "  5300 / 7705 (54.250862)\n",
      "  5400 / 7705 (554.433868)\n",
      "  5500 / 7705 (249.612419)\n",
      "  5600 / 7705 (4.506072)\n",
      "  5700 / 7705 (895.513458)\n",
      "  5800 / 7705 (679.916895)\n",
      "  5900 / 7705 (37.159599)\n",
      "  6000 / 7705 (646.049934)\n",
      "  6100 / 7705 (83.090317)\n",
      "  6200 / 7705 (159.054253)\n",
      "  6300 / 7705 (303.565430)\n",
      "  6400 / 7705 (120.448288)\n",
      "  6500 / 7705 (45.338290)\n",
      "  6600 / 7705 (962.621872)\n",
      "  6700 / 7705 (800.049866)\n",
      "  6800 / 7705 (197.058342)\n",
      "  6900 / 7705 (84.051979)\n",
      "  7000 / 7705 (57.052391)\n",
      "  7100 / 7705 (157.336212)\n",
      "  7200 / 7705 (947.251770)\n",
      "  7300 / 7705 (189.113571)\n",
      "  7400 / 7705 (279.504957)\n",
      "  7500 / 7705 (55.066116)\n",
      "  7600 / 7705 (564.346340)\n",
      "  7700 / 7705 (674.084511)\n",
      "False scores...\n",
      "  0 / 7705 (199.337280)\n",
      "  100 / 7705 (70.109215)\n",
      "  200 / 7705 (227.542860)\n",
      "  300 / 7705 (1043.111534)\n",
      "  400 / 7705 (914.083145)\n",
      "  500 / 7705 (1109.885834)\n",
      "  600 / 7705 (153.383453)\n",
      "  700 / 7705 (324.631207)\n",
      "  800 / 7705 (191.134308)\n",
      "  900 / 7705 (339.444527)\n",
      "  1000 / 7705 (367.880516)\n",
      "  1100 / 7705 (649.086472)\n",
      "  1200 / 7705 (232.442753)\n",
      "  1300 / 7705 (199.341290)\n",
      "  1400 / 7705 (455.209251)\n",
      "  1500 / 7705 (62.141182)\n",
      "  1600 / 7705 (491.092216)\n",
      "  1700 / 7705 (399.722511)\n",
      "  1800 / 7705 (466.715225)\n",
      "  1900 / 7705 (275.879791)\n",
      "  2000 / 7705 (444.048454)\n",
      "  2100 / 7705 (658.512253)\n",
      "  2200 / 7705 (123.886200)\n",
      "  2300 / 7705 (897.965057)\n",
      "  2400 / 7705 (81.516708)\n",
      "  2500 / 7705 (142.128769)\n",
      "  2600 / 7705 (373.589119)\n",
      "  2700 / 7705 (300.838074)\n",
      "  2800 / 7705 (415.252350)\n",
      "  2900 / 7705 (321.008972)\n",
      "  3000 / 7705 (223.553345)\n",
      "  3100 / 7705 (133.212067)\n",
      "  3200 / 7705 (136.982742)\n",
      "  3300 / 7705 (865.135818)\n",
      "  3400 / 7705 (811.589142)\n",
      "  3500 / 7705 (62.075172)\n",
      "  3600 / 7705 (797.465282)\n",
      "  3700 / 7705 (57.804722)\n",
      "  3800 / 7705 (451.786087)\n",
      "  3900 / 7705 (97.431396)\n",
      "  4000 / 7705 (80.128128)\n",
      "  4100 / 7705 (123.021629)\n",
      "  4200 / 7705 (291.725670)\n",
      "  4300 / 7705 (124.787766)\n",
      "  4400 / 7705 (135.868988)\n",
      "  4500 / 7705 (592.947693)\n",
      "  4600 / 7705 (64.937035)\n",
      "  4700 / 7705 (161.307823)\n",
      "  4800 / 7705 (483.242706)\n",
      "  4900 / 7705 (41.761627)\n",
      "  5000 / 7705 (90.611664)\n",
      "  5100 / 7705 (547.376541)\n",
      "  5200 / 7705 (111.274345)\n",
      "  5300 / 7705 (56.069893)\n",
      "  5400 / 7705 (554.406082)\n",
      "  5500 / 7705 (250.355797)\n",
      "  5600 / 7705 (4.249064)\n",
      "  5700 / 7705 (878.920143)\n",
      "  5800 / 7705 (667.815651)\n",
      "  5900 / 7705 (39.300087)\n",
      "  6000 / 7705 (631.337143)\n",
      "  6100 / 7705 (82.235603)\n",
      "  6200 / 7705 (160.345497)\n",
      "  6300 / 7705 (298.844849)\n",
      "  6400 / 7705 (126.952538)\n",
      "  6500 / 7705 (46.884022)\n",
      "  6600 / 7705 (944.003677)\n",
      "  6700 / 7705 (792.796204)\n",
      "  6800 / 7705 (192.193024)\n",
      "  6900 / 7705 (83.060036)\n",
      "  7000 / 7705 (55.086937)\n",
      "  7100 / 7705 (153.096146)\n",
      "  7200 / 7705 (938.401642)\n",
      "  7300 / 7705 (188.566513)\n",
      "  7400 / 7705 (276.843735)\n",
      "  7500 / 7705 (56.571587)\n",
      "  7600 / 7705 (558.699364)\n",
      "  7700 / 7705 (667.978722)\n",
      "Generating validation set...\n",
      "True scores...\n",
      "  0 / 5000 (4.506072)\n",
      "  100 / 5000 (15.130462)\n",
      "  200 / 5000 (24.092087)\n",
      "  300 / 5000 (383.940559)\n",
      "  400 / 5000 (89.241196)\n",
      "  500 / 5000 (614.155975)\n",
      "  600 / 5000 (358.075836)\n",
      "  700 / 5000 (405.877380)\n",
      "  800 / 5000 (94.010056)\n",
      "  900 / 5000 (663.571671)\n",
      "  1000 / 5000 (409.858734)\n",
      "  1100 / 5000 (844.718231)\n",
      "  1200 / 5000 (1075.904732)\n",
      "  1300 / 5000 (804.410477)\n",
      "  1400 / 5000 (624.380539)\n",
      "  1500 / 5000 (177.249416)\n",
      "  1600 / 5000 (131.098145)\n",
      "  1700 / 5000 (605.935242)\n",
      "  1800 / 5000 (266.812988)\n",
      "  1900 / 5000 (101.059082)\n",
      "  2000 / 5000 (256.857624)\n",
      "  2100 / 5000 (131.035553)\n",
      "  2200 / 5000 (161.172455)\n",
      "  2300 / 5000 (410.032295)\n",
      "  2400 / 5000 (520.801956)\n",
      "  2500 / 5000 (208.783386)\n",
      "  2600 / 5000 (344.178699)\n",
      "  2700 / 5000 (41.894142)\n",
      "  2800 / 5000 (621.910301)\n",
      "  2900 / 5000 (862.340647)\n",
      "  3000 / 5000 (185.484070)\n",
      "  3100 / 5000 (6.229780)\n",
      "  3200 / 5000 (902.078473)\n",
      "  3300 / 5000 (107.419464)\n",
      "  3400 / 5000 (970.947296)\n",
      "  3500 / 5000 (263.367432)\n",
      "  3600 / 5000 (66.261246)\n",
      "  3700 / 5000 (91.806686)\n",
      "  3800 / 5000 (530.093201)\n",
      "  3900 / 5000 (369.254517)\n",
      "  4000 / 5000 (45.284576)\n",
      "  4100 / 5000 (70.685913)\n",
      "  4200 / 5000 (597.894867)\n",
      "  4300 / 5000 (377.623367)\n",
      "  4400 / 5000 (259.354942)\n",
      "  4500 / 5000 (206.245992)\n",
      "  4600 / 5000 (102.802456)\n",
      "  4700 / 5000 (175.512955)\n",
      "  4800 / 5000 (107.804606)\n",
      "  4900 / 5000 (125.876996)\n",
      "False scores...\n",
      "  0 / 5000 (4.249064)\n",
      "  100 / 5000 (14.721357)\n",
      "  200 / 5000 (24.528564)\n",
      "  300 / 5000 (379.147320)\n",
      "  400 / 5000 (83.796463)\n",
      "  500 / 5000 (597.833923)\n",
      "  600 / 5000 (356.764450)\n",
      "  700 / 5000 (383.059509)\n",
      "  800 / 5000 (97.142456)\n",
      "  900 / 5000 (646.633568)\n",
      "  1000 / 5000 (398.876892)\n",
      "  1100 / 5000 (837.729469)\n",
      "  1200 / 5000 (1059.898247)\n",
      "  1300 / 5000 (800.272087)\n",
      "  1400 / 5000 (598.532867)\n",
      "  1500 / 5000 (171.964869)\n",
      "  1600 / 5000 (129.309250)\n",
      "  1700 / 5000 (593.608887)\n",
      "  1800 / 5000 (269.637543)\n",
      "  1900 / 5000 (102.304932)\n",
      "  2000 / 5000 (257.829651)\n",
      "  2100 / 5000 (128.258476)\n",
      "  2200 / 5000 (162.419159)\n",
      "  2300 / 5000 (399.918533)\n",
      "  2400 / 5000 (518.434120)\n",
      "  2500 / 5000 (208.513199)\n",
      "  2600 / 5000 (353.257973)\n",
      "  2700 / 5000 (44.571396)\n",
      "  2800 / 5000 (615.355316)\n",
      "  2900 / 5000 (850.652728)\n",
      "  3000 / 5000 (183.791840)\n",
      "  3100 / 5000 (6.072772)\n",
      "  3200 / 5000 (876.400870)\n",
      "  3300 / 5000 (108.203995)\n",
      "  3400 / 5000 (959.932587)\n",
      "  3500 / 5000 (260.521790)\n",
      "  3600 / 5000 (66.029793)\n",
      "  3700 / 5000 (93.510536)\n",
      "  3800 / 5000 (515.765320)\n",
      "  3900 / 5000 (372.044098)\n",
      "  4000 / 5000 (43.295837)\n",
      "  4100 / 5000 (72.266151)\n",
      "  4200 / 5000 (588.235062)\n",
      "  4300 / 5000 (378.861679)\n",
      "  4400 / 5000 (257.783871)\n",
      "  4500 / 5000 (201.938547)\n",
      "  4600 / 5000 (103.556782)\n",
      "  4700 / 5000 (180.856232)\n",
      "  4800 / 5000 (100.592278)\n",
      "  4900 / 5000 (123.956034)\n",
      "Generating test set...\n",
      "True scores...\n",
      "  0 / 5000 (358.221164)\n",
      "  100 / 5000 (575.199188)\n",
      "  200 / 5000 (803.476395)\n",
      "  300 / 5000 (23.818945)\n",
      "  400 / 5000 (91.426254)\n",
      "  500 / 5000 (160.420227)\n",
      "  600 / 5000 (153.547501)\n",
      "  700 / 5000 (238.151833)\n",
      "  800 / 5000 (959.205208)\n",
      "  900 / 5000 (222.476685)\n",
      "  1000 / 5000 (339.907690)\n",
      "  1100 / 5000 (822.867737)\n",
      "  1200 / 5000 (858.039456)\n",
      "  1300 / 5000 (82.847076)\n",
      "  1400 / 5000 (692.008011)\n",
      "  1500 / 5000 (61.964546)\n",
      "  1600 / 5000 (437.398560)\n",
      "  1700 / 5000 (912.440269)\n",
      "  1800 / 5000 (416.981709)\n",
      "  1900 / 5000 (73.469154)\n",
      "  2000 / 5000 (31.249769)\n",
      "  2100 / 5000 (89.475769)\n",
      "  2200 / 5000 (792.819214)\n",
      "  2300 / 5000 (255.094810)\n",
      "  2400 / 5000 (88.654472)\n",
      "  2500 / 5000 (505.540222)\n",
      "  2600 / 5000 (200.671127)\n",
      "  2700 / 5000 (1010.963211)\n",
      "  2800 / 5000 (349.034775)\n",
      "  2900 / 5000 (695.154663)\n",
      "  3000 / 5000 (104.901260)\n",
      "  3100 / 5000 (181.703537)\n",
      "  3200 / 5000 (480.366074)\n",
      "  3300 / 5000 (549.159019)\n",
      "  3400 / 5000 (188.751122)\n",
      "  3500 / 5000 (117.650917)\n",
      "  3600 / 5000 (73.604599)\n",
      "  3700 / 5000 (837.234329)\n",
      "  3800 / 5000 (59.686459)\n",
      "  3900 / 5000 (347.161400)\n",
      "  4000 / 5000 (246.240189)\n",
      "  4100 / 5000 (31.772932)\n",
      "  4200 / 5000 (660.557247)\n",
      "  4300 / 5000 (76.200241)\n",
      "  4400 / 5000 (943.552490)\n",
      "  4500 / 5000 (219.293304)\n",
      "  4600 / 5000 (295.695133)\n",
      "  4700 / 5000 (700.416618)\n",
      "  4800 / 5000 (164.814373)\n",
      "  4900 / 5000 (373.151062)\n",
      "False scores...\n",
      "  0 / 5000 (356.653460)\n",
      "  100 / 5000 (557.716400)\n",
      "  200 / 5000 (785.626373)\n",
      "  300 / 5000 (25.315044)\n",
      "  400 / 5000 (97.090462)\n",
      "  500 / 5000 (160.664467)\n",
      "  600 / 5000 (149.758865)\n",
      "  700 / 5000 (242.752449)\n",
      "  800 / 5000 (956.055397)\n",
      "  900 / 5000 (220.099777)\n",
      "  1000 / 5000 (334.175903)\n",
      "  1100 / 5000 (811.154613)\n",
      "  1200 / 5000 (839.047552)\n",
      "  1300 / 5000 (82.823807)\n",
      "  1400 / 5000 (697.693634)\n",
      "  1500 / 5000 (61.641518)\n",
      "  1600 / 5000 (434.976837)\n",
      "  1700 / 5000 (913.618006)\n",
      "  1800 / 5000 (413.336330)\n",
      "  1900 / 5000 (74.362122)\n",
      "  2000 / 5000 (30.978374)\n",
      "  2100 / 5000 (84.134483)\n",
      "  2200 / 5000 (785.773685)\n",
      "  2300 / 5000 (250.550217)\n",
      "  2400 / 5000 (87.208031)\n",
      "  2500 / 5000 (494.214890)\n",
      "  2600 / 5000 (183.342331)\n",
      "  2700 / 5000 (990.877899)\n",
      "  2800 / 5000 (338.319595)\n",
      "  2900 / 5000 (679.741638)\n",
      "  3000 / 5000 (103.249817)\n",
      "  3100 / 5000 (185.997971)\n",
      "  3200 / 5000 (479.964142)\n",
      "  3300 / 5000 (555.497208)\n",
      "  3400 / 5000 (187.001221)\n",
      "  3500 / 5000 (117.049416)\n",
      "  3600 / 5000 (71.943932)\n",
      "  3700 / 5000 (829.858566)\n",
      "  3800 / 5000 (61.415890)\n",
      "  3900 / 5000 (346.749435)\n",
      "  4000 / 5000 (251.956268)\n",
      "  4100 / 5000 (31.498257)\n",
      "  4200 / 5000 (648.436230)\n",
      "  4300 / 5000 (73.757835)\n",
      "  4400 / 5000 (914.374966)\n",
      "  4500 / 5000 (219.035233)\n",
      "  4600 / 5000 (284.359184)\n",
      "  4700 / 5000 (694.150665)\n",
      "  4800 / 5000 (163.946079)\n",
      "  4900 / 5000 (375.664001)\n",
      "Writing to disk...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "reload(common)\n",
    "common.extract_features(\n",
    "    \"ka-replies-balanced\",\n",
    "    RNNClassifierFeatureExtractor(corpus, model_params, \"true_all\", \"false_all\"),\n",
    "    \"reply-rnn\", sampling=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features reply-rnn.\n",
      "Training models.\n",
      "##        MultinomialNB       reply-rnn precision: 0.0% recall: 0.0%\n",
      "##            LinearSVC       reply-rnn precision: 49.1% recall: 62.2%\n",
      "##                  MLP       reply-rnn precision: 48.2% recall: 61.6%\n",
      "##                 MLP2       reply-rnn precision: 49.0% recall: 64.3%\n"
     ]
    }
   ],
   "source": [
    "reload(common)\n",
    "common.test_features(\"reply-rnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print \"Loading dataset...\"\n",
    "with open(\"/usr/src/app/data/ka-rank-balanced.pickle\", \"rb\") as f:\n",
    "    ranks_dataset = pickle.load(f)    \n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "model_params = rnnlm.RNNParams(V=100000, H=250, num_layers=2)\n",
    "train_params = {\n",
    "    \"max_time\": 20,\n",
    "    \"batch_size\": 50,\n",
    "    \"learning_rate\": 0.0025,\n",
    "    \"keep_prob\": 0.5,\n",
    "    \"num_epochs\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "ranks_corpus = processing.Corpus(ranks_dataset[\"train_data\"][\"content\"], model_params.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding sentences...\n",
      "Processing sentences...\n",
      "Loaded 13647 sentences (242364 tokens)\n",
      "Training set: 10917 sentences (192928 tokens)\n",
      "Test set: 2730 sentences (49436 tokens)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "mini_training_data = ranks_corpus.generate_training_data(\n",
    "    ranks_dataset[\"train_data\"].iloc[:5000][\"content\"],\n",
    "    train_frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 46]: seen 47000 words at 4667 wps, loss = 7.306\n",
      "[batch 96]: seen 97000 words at 4787 wps, loss = 6.649\n",
      "[batch 142]: seen 143000 words at 4715 wps, loss = 6.416\n",
      "[batch 191]: seen 192000 words at 4743 wps, loss = 6.228\n",
      "[epoch 1] Completed in 0:00:43\n",
      "[epoch 1] [batch 5]: seen 52100 words at 5130 wps, loss = 5.614\n",
      "Test set: avg. loss: 5.614  (perplexity: 274.15)\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[batch 46]: seen 47000 words at 4699 wps, loss = 5.512\n",
      "[batch 94]: seen 95000 words at 4704 wps, loss = 5.428\n",
      "[batch 142]: seen 143000 words at 4703 wps, loss = 5.376\n",
      "[batch 186]: seen 187000 words at 4615 wps, loss = 5.345\n",
      "[epoch 2] Completed in 0:00:43\n",
      "[epoch 2] Test set: avg. loss: 4.951  (perplexity: 141.29)\n",
      "\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(ranks_corpus, mini_training_data, \"ranks_test\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding sentences...\n",
      "Processing sentences...\n",
      "Loaded 497273 sentences (8.36499e+06 tokens)\n",
      "Training set: 472409 sentences (7947856 tokens)\n",
      "Test set: 24864 sentences (417133 tokens)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "top_training_data = ranks_corpus.generate_training_data(\n",
    "    ranks_dataset[\"train_data\"][ranks_dataset[\"train_data\"][\"topRank\"] == True][\"content\"],\n",
    "    train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 42]: seen 43000 words at 4296 wps, loss = 7.316\n",
      "[batch 85]: seen 86000 words at 4273 wps, loss = 6.642\n",
      "[batch 132]: seen 133000 words at 4406 wps, loss = 6.372\n",
      "[batch 175]: seen 176000 words at 4360 wps, loss = 6.183\n",
      "[batch 220]: seen 221000 words at 4375 wps, loss = 6.026\n",
      "[batch 268]: seen 269000 words at 4440 wps, loss = 5.921\n",
      "[batch 314]: seen 315000 words at 4460 wps, loss = 5.823\n",
      "[batch 362]: seen 363000 words at 4490 wps, loss = 5.741\n",
      "[batch 407]: seen 408000 words at 4479 wps, loss = 5.674\n",
      "[batch 455]: seen 456000 words at 4508 wps, loss = 5.616\n",
      "[batch 502]: seen 503000 words at 4524 wps, loss = 5.562\n",
      "[batch 545]: seen 546000 words at 4499 wps, loss = 5.519\n",
      "[batch 585]: seen 586000 words at 4459 wps, loss = 5.482\n",
      "[batch 629]: seen 630000 words at 4447 wps, loss = 5.446\n",
      "[batch 672]: seen 673000 words at 4431 wps, loss = 5.415\n",
      "[batch 720]: seen 721000 words at 4452 wps, loss = 5.384\n",
      "[batch 766]: seen 767000 words at 4457 wps, loss = 5.357\n",
      "[batch 813]: seen 814000 words at 4468 wps, loss = 5.332\n",
      "[batch 860]: seen 861000 words at 4477 wps, loss = 5.307\n",
      "[batch 905]: seen 906000 words at 4478 wps, loss = 5.286\n",
      "[batch 952]: seen 953000 words at 4488 wps, loss = 5.264\n",
      "[batch 998]: seen 999000 words at 4491 wps, loss = 5.243\n",
      "[batch 1046]: seen 1047000 words at 4504 wps, loss = 5.224\n",
      "[batch 1094]: seen 1095000 words at 4513 wps, loss = 5.205\n",
      "[batch 1137]: seen 1138000 words at 4503 wps, loss = 5.187\n",
      "[batch 1185]: seen 1186000 words at 4507 wps, loss = 5.170\n",
      "[batch 1233]: seen 1234000 words at 4516 wps, loss = 5.153\n",
      "[batch 1280]: seen 1281000 words at 4522 wps, loss = 5.137\n",
      "[batch 1327]: seen 1328000 words at 4527 wps, loss = 5.122\n",
      "[batch 1372]: seen 1373000 words at 4522 wps, loss = 5.109\n",
      "[batch 1418]: seen 1419000 words at 4524 wps, loss = 5.097\n",
      "[batch 1465]: seen 1466000 words at 4529 wps, loss = 5.085\n",
      "[batch 1510]: seen 1511000 words at 4528 wps, loss = 5.074\n",
      "[batch 1557]: seen 1558000 words at 4530 wps, loss = 5.063\n",
      "[batch 1604]: seen 1605000 words at 4534 wps, loss = 5.051\n",
      "[batch 1652]: seen 1653000 words at 4539 wps, loss = 5.040\n",
      "[batch 1699]: seen 1700000 words at 4542 wps, loss = 5.030\n",
      "[batch 1745]: seen 1746000 words at 4542 wps, loss = 5.021\n",
      "[batch 1794]: seen 1795000 words at 4550 wps, loss = 5.011\n",
      "[batch 1840]: seen 1841000 words at 4551 wps, loss = 5.002\n",
      "[batch 1886]: seen 1887000 words at 4550 wps, loss = 4.994\n",
      "[batch 1933]: seen 1934000 words at 4553 wps, loss = 4.984\n",
      "[batch 1979]: seen 1980000 words at 4553 wps, loss = 4.975\n",
      "[batch 2024]: seen 2025000 words at 4549 wps, loss = 4.966\n",
      "[batch 2071]: seen 2072000 words at 4552 wps, loss = 4.959\n",
      "[batch 2118]: seen 2119000 words at 4554 wps, loss = 4.952\n",
      "[batch 2166]: seen 2167000 words at 4558 wps, loss = 4.943\n",
      "[batch 2213]: seen 2214000 words at 4560 wps, loss = 4.935\n",
      "[batch 2260]: seen 2261000 words at 4562 wps, loss = 4.927\n",
      "[batch 2303]: seen 2304000 words at 4556 wps, loss = 4.921\n",
      "[batch 2352]: seen 2353000 words at 4563 wps, loss = 4.913\n",
      "[batch 2400]: seen 2401000 words at 4567 wps, loss = 4.907\n",
      "[batch 2439]: seen 2440000 words at 4554 wps, loss = 4.901\n",
      "[batch 2478]: seen 2479000 words at 4541 wps, loss = 4.896\n",
      "[batch 2512]: seen 2513000 words at 4521 wps, loss = 4.891\n",
      "[batch 2556]: seen 2557000 words at 4517 wps, loss = 4.885\n",
      "[batch 2593]: seen 2594000 words at 4502 wps, loss = 4.881\n",
      "[batch 2637]: seen 2638000 words at 4500 wps, loss = 4.875\n",
      "[batch 2684]: seen 2685000 words at 4503 wps, loss = 4.870\n",
      "[batch 2731]: seen 2732000 words at 4505 wps, loss = 4.863\n",
      "[batch 2780]: seen 2781000 words at 4511 wps, loss = 4.857\n",
      "[batch 2829]: seen 2830000 words at 4516 wps, loss = 4.851\n",
      "[batch 2877]: seen 2878000 words at 4519 wps, loss = 4.847\n",
      "[batch 2924]: seen 2925000 words at 4521 wps, loss = 4.841\n",
      "[batch 2970]: seen 2971000 words at 4521 wps, loss = 4.836\n",
      "[batch 3018]: seen 3019000 words at 4524 wps, loss = 4.830\n",
      "[batch 3065]: seen 3066000 words at 4525 wps, loss = 4.825\n",
      "[batch 3110]: seen 3111000 words at 4524 wps, loss = 4.821\n",
      "[batch 3155]: seen 3156000 words at 4523 wps, loss = 4.817\n",
      "[batch 3203]: seen 3204000 words at 4526 wps, loss = 4.812\n",
      "[batch 3252]: seen 3253000 words at 4530 wps, loss = 4.807\n",
      "[batch 3301]: seen 3302000 words at 4534 wps, loss = 4.803\n",
      "[batch 3348]: seen 3349000 words at 4536 wps, loss = 4.798\n",
      "[batch 3394]: seen 3395000 words at 4536 wps, loss = 4.794\n",
      "[batch 3441]: seen 3442000 words at 4538 wps, loss = 4.790\n",
      "[batch 3489]: seen 3490000 words at 4541 wps, loss = 4.785\n",
      "[batch 3537]: seen 3538000 words at 4543 wps, loss = 4.781\n",
      "[batch 3580]: seen 3581000 words at 4539 wps, loss = 4.778\n",
      "[batch 3628]: seen 3629000 words at 4541 wps, loss = 4.774\n",
      "[batch 3676]: seen 3677000 words at 4543 wps, loss = 4.770\n",
      "[batch 3724]: seen 3725000 words at 4546 wps, loss = 4.766\n",
      "[batch 3772]: seen 3773000 words at 4548 wps, loss = 4.762\n",
      "[batch 3816]: seen 3817000 words at 4546 wps, loss = 4.758\n",
      "[batch 3862]: seen 3863000 words at 4546 wps, loss = 4.755\n",
      "[batch 3897]: seen 3898000 words at 4533 wps, loss = 4.752\n",
      "[batch 3933]: seen 3934000 words at 4522 wps, loss = 4.749\n",
      "[batch 3983]: seen 3984000 words at 4526 wps, loss = 4.745\n",
      "[batch 4027]: seen 4028000 words at 4524 wps, loss = 4.742\n",
      "[batch 4073]: seen 4074000 words at 4524 wps, loss = 4.738\n",
      "[batch 4117]: seen 4118000 words at 4522 wps, loss = 4.734\n",
      "[batch 4166]: seen 4167000 words at 4526 wps, loss = 4.731\n",
      "[batch 4214]: seen 4215000 words at 4529 wps, loss = 4.727\n",
      "[batch 4261]: seen 4262000 words at 4530 wps, loss = 4.724\n",
      "[batch 4306]: seen 4307000 words at 4530 wps, loss = 4.720\n",
      "[batch 4350]: seen 4351000 words at 4527 wps, loss = 4.717\n",
      "[batch 4394]: seen 4395000 words at 4525 wps, loss = 4.714\n",
      "[batch 4441]: seen 4442000 words at 4526 wps, loss = 4.711\n",
      "[batch 4489]: seen 4490000 words at 4529 wps, loss = 4.708\n",
      "[batch 4536]: seen 4537000 words at 4530 wps, loss = 4.705\n",
      "[batch 4584]: seen 4585000 words at 4532 wps, loss = 4.702\n",
      "[batch 4623]: seen 4624000 words at 4525 wps, loss = 4.700\n",
      "[batch 4661]: seen 4662000 words at 4517 wps, loss = 4.697\n",
      "[batch 4700]: seen 4701000 words at 4510 wps, loss = 4.694\n",
      "[batch 4744]: seen 4745000 words at 4509 wps, loss = 4.692\n",
      "[batch 4791]: seen 4792000 words at 4510 wps, loss = 4.689\n",
      "[batch 4840]: seen 4841000 words at 4513 wps, loss = 4.686\n",
      "[batch 4889]: seen 4890000 words at 4516 wps, loss = 4.683\n",
      "[batch 4938]: seen 4939000 words at 4519 wps, loss = 4.680\n",
      "[batch 4983]: seen 4984000 words at 4519 wps, loss = 4.677\n",
      "[batch 5033]: seen 5034000 words at 4522 wps, loss = 4.675\n",
      "[batch 5082]: seen 5083000 words at 4525 wps, loss = 4.672\n",
      "[batch 5131]: seen 5132000 words at 4528 wps, loss = 4.669\n",
      "[batch 5180]: seen 5181000 words at 4531 wps, loss = 4.666\n",
      "[batch 5227]: seen 5228000 words at 4532 wps, loss = 4.664\n",
      "[batch 5272]: seen 5273000 words at 4531 wps, loss = 4.661\n",
      "[batch 5319]: seen 5320000 words at 4532 wps, loss = 4.659\n",
      "[batch 5365]: seen 5366000 words at 4532 wps, loss = 4.656\n",
      "[batch 5414]: seen 5415000 words at 4535 wps, loss = 4.654\n",
      "[batch 5461]: seen 5462000 words at 4536 wps, loss = 4.651\n",
      "[batch 5510]: seen 5511000 words at 4539 wps, loss = 4.649\n",
      "[batch 5557]: seen 5558000 words at 4540 wps, loss = 4.646\n",
      "[batch 5603]: seen 5604000 words at 4541 wps, loss = 4.644\n",
      "[batch 5650]: seen 5651000 words at 4542 wps, loss = 4.641\n",
      "[batch 5692]: seen 5693000 words at 4538 wps, loss = 4.639\n",
      "[batch 5740]: seen 5741000 words at 4540 wps, loss = 4.636\n",
      "[batch 5784]: seen 5785000 words at 4539 wps, loss = 4.634\n",
      "[batch 5833]: seen 5834000 words at 4541 wps, loss = 4.632\n",
      "[batch 5881]: seen 5882000 words at 4543 wps, loss = 4.629\n",
      "[batch 5931]: seen 5932000 words at 4546 wps, loss = 4.627\n",
      "[batch 5980]: seen 5981000 words at 4548 wps, loss = 4.625\n",
      "[batch 6026]: seen 6027000 words at 4548 wps, loss = 4.622\n",
      "[batch 6075]: seen 6076000 words at 4550 wps, loss = 4.620\n",
      "[batch 6120]: seen 6121000 words at 4550 wps, loss = 4.618\n",
      "[batch 6164]: seen 6165000 words at 4548 wps, loss = 4.616\n",
      "[batch 6210]: seen 6211000 words at 4549 wps, loss = 4.614\n",
      "[batch 6258]: seen 6259000 words at 4550 wps, loss = 4.612\n",
      "[batch 6307]: seen 6308000 words at 4553 wps, loss = 4.609\n",
      "[batch 6351]: seen 6352000 words at 4551 wps, loss = 4.607\n",
      "[batch 6394]: seen 6395000 words at 4549 wps, loss = 4.605\n",
      "[batch 6438]: seen 6439000 words at 4548 wps, loss = 4.603\n",
      "[batch 6482]: seen 6483000 words at 4547 wps, loss = 4.601\n",
      "[batch 6527]: seen 6528000 words at 4546 wps, loss = 4.600\n",
      "[batch 6575]: seen 6576000 words at 4547 wps, loss = 4.597\n",
      "[batch 6625]: seen 6626000 words at 4550 wps, loss = 4.595\n",
      "[batch 6675]: seen 6676000 words at 4553 wps, loss = 4.593\n",
      "[batch 6725]: seen 6726000 words at 4555 wps, loss = 4.591\n",
      "[batch 6775]: seen 6776000 words at 4558 wps, loss = 4.589\n",
      "[batch 6823]: seen 6824000 words at 4560 wps, loss = 4.587\n",
      "[batch 6869]: seen 6870000 words at 4560 wps, loss = 4.585\n",
      "[batch 6919]: seen 6920000 words at 4563 wps, loss = 4.583\n",
      "[batch 6968]: seen 6969000 words at 4565 wps, loss = 4.582\n",
      "[batch 7018]: seen 7019000 words at 4567 wps, loss = 4.579\n",
      "[batch 7047]: seen 7048000 words at 4556 wps, loss = 4.578\n",
      "[batch 7093]: seen 7094000 words at 4556 wps, loss = 4.577\n",
      "[batch 7135]: seen 7136000 words at 4553 wps, loss = 4.575\n",
      "[batch 7182]: seen 7183000 words at 4554 wps, loss = 4.574\n",
      "[batch 7230]: seen 7231000 words at 4555 wps, loss = 4.572\n",
      "[batch 7277]: seen 7278000 words at 4556 wps, loss = 4.570\n",
      "[batch 7327]: seen 7328000 words at 4558 wps, loss = 4.568\n",
      "[batch 7378]: seen 7379000 words at 4561 wps, loss = 4.566\n",
      "[batch 7429]: seen 7430000 words at 4564 wps, loss = 4.564\n",
      "[batch 7480]: seen 7481000 words at 4567 wps, loss = 4.562\n",
      "[batch 7529]: seen 7530000 words at 4569 wps, loss = 4.561\n",
      "[batch 7579]: seen 7580000 words at 4571 wps, loss = 4.559\n",
      "[batch 7630]: seen 7631000 words at 4574 wps, loss = 4.557\n",
      "[batch 7681]: seen 7682000 words at 4577 wps, loss = 4.556\n",
      "[batch 7732]: seen 7733000 words at 4579 wps, loss = 4.554\n",
      "[batch 7783]: seen 7784000 words at 4582 wps, loss = 4.552\n",
      "[batch 7834]: seen 7835000 words at 4585 wps, loss = 4.550\n",
      "[batch 7882]: seen 7883000 words at 4586 wps, loss = 4.549\n",
      "[batch 7933]: seen 7934000 words at 4589 wps, loss = 4.547\n",
      "[batch 7984]: seen 7985000 words at 4591 wps, loss = 4.545\n",
      "[batch 8034]: seen 8035000 words at 4593 wps, loss = 4.543\n",
      "[batch 8085]: seen 8086000 words at 4596 wps, loss = 4.542\n",
      "[batch 8136]: seen 8137000 words at 4599 wps, loss = 4.540\n",
      "[batch 8187]: seen 8188000 words at 4601 wps, loss = 4.538\n",
      "[batch 8238]: seen 8239000 words at 4604 wps, loss = 4.537\n",
      "[batch 8289]: seen 8290000 words at 4606 wps, loss = 4.535\n",
      "[batch 8340]: seen 8341000 words at 4609 wps, loss = 4.533\n",
      "[batch 8390]: seen 8391000 words at 4611 wps, loss = 4.531\n",
      "[epoch 1] Completed in 0:30:26\n",
      "[epoch 1] [batch 4]: seen 50000 words at 4501 wps, loss = 4.025\n",
      "[batch 10]: seen 110000 words at 4957 wps, loss = 4.012\n",
      "[batch 16]: seen 170000 words at 5036 wps, loss = 4.000\n",
      "[batch 22]: seen 230000 words at 5155 wps, loss = 3.991\n",
      "[batch 28]: seen 290000 words at 5196 wps, loss = 3.981\n",
      "[batch 34]: seen 350000 words at 5241 wps, loss = 3.975\n",
      "[batch 40]: seen 410000 words at 5274 wps, loss = 3.974\n",
      "Test set: avg. loss: 3.969  (perplexity: 52.92)\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[batch 47]: seen 48000 words at 4735 wps, loss = 4.255\n",
      "[batch 94]: seen 95000 words at 4666 wps, loss = 4.259\n",
      "[batch 141]: seen 142000 words at 4673 wps, loss = 4.252\n",
      "[batch 190]: seen 191000 words at 4719 wps, loss = 4.253\n",
      "[batch 240]: seen 241000 words at 4771 wps, loss = 4.258\n",
      "[batch 291]: seen 292000 words at 4819 wps, loss = 4.260\n",
      "[batch 342]: seen 343000 words at 4850 wps, loss = 4.255\n",
      "[batch 392]: seen 393000 words at 4858 wps, loss = 4.253\n",
      "[batch 439]: seen 440000 words at 4834 wps, loss = 4.249\n",
      "[batch 490]: seen 491000 words at 4857 wps, loss = 4.247\n",
      "[batch 539]: seen 540000 words at 4859 wps, loss = 4.245\n",
      "[batch 589]: seen 590000 words at 4867 wps, loss = 4.243\n",
      "[batch 640]: seen 641000 words at 4880 wps, loss = 4.243\n",
      "[batch 690]: seen 691000 words at 4888 wps, loss = 4.244\n",
      "[batch 740]: seen 741000 words at 4894 wps, loss = 4.244\n",
      "[batch 791]: seen 792000 words at 4903 wps, loss = 4.242\n",
      "[batch 842]: seen 843000 words at 4911 wps, loss = 4.243\n",
      "[batch 893]: seen 894000 words at 4917 wps, loss = 4.243\n",
      "[batch 944]: seen 945000 words at 4923 wps, loss = 4.243\n",
      "[batch 995]: seen 996000 words at 4927 wps, loss = 4.241\n",
      "[batch 1046]: seen 1047000 words at 4932 wps, loss = 4.241\n",
      "[batch 1097]: seen 1098000 words at 4936 wps, loss = 4.240\n",
      "[batch 1145]: seen 1146000 words at 4929 wps, loss = 4.238\n",
      "[batch 1196]: seen 1197000 words at 4932 wps, loss = 4.236\n",
      "[batch 1247]: seen 1248000 words at 4937 wps, loss = 4.235\n",
      "[batch 1296]: seen 1297000 words at 4935 wps, loss = 4.234\n",
      "[batch 1346]: seen 1347000 words at 4936 wps, loss = 4.234\n",
      "[batch 1397]: seen 1398000 words at 4940 wps, loss = 4.233\n",
      "[batch 1448]: seen 1449000 words at 4942 wps, loss = 4.233\n",
      "[batch 1498]: seen 1499000 words at 4942 wps, loss = 4.234\n",
      "[batch 1549]: seen 1550000 words at 4945 wps, loss = 4.233\n",
      "[batch 1599]: seen 1600000 words at 4944 wps, loss = 4.232\n",
      "[batch 1649]: seen 1650000 words at 4943 wps, loss = 4.231\n",
      "[batch 1699]: seen 1700000 words at 4944 wps, loss = 4.231\n",
      "[batch 1750]: seen 1751000 words at 4946 wps, loss = 4.231\n",
      "[batch 1795]: seen 1796000 words at 4931 wps, loss = 4.231\n",
      "[batch 1844]: seen 1845000 words at 4929 wps, loss = 4.231\n",
      "[batch 1895]: seen 1896000 words at 4931 wps, loss = 4.231\n",
      "[batch 1944]: seen 1945000 words at 4930 wps, loss = 4.229\n",
      "[batch 1991]: seen 1992000 words at 4922 wps, loss = 4.228\n",
      "[batch 2041]: seen 2042000 words at 4922 wps, loss = 4.228\n",
      "[batch 2091]: seen 2092000 words at 4922 wps, loss = 4.227\n",
      "[batch 2141]: seen 2142000 words at 4924 wps, loss = 4.227\n",
      "[batch 2191]: seen 2192000 words at 4924 wps, loss = 4.225\n",
      "[batch 2241]: seen 2242000 words at 4925 wps, loss = 4.225\n",
      "[batch 2292]: seen 2293000 words at 4928 wps, loss = 4.224\n",
      "[batch 2342]: seen 2343000 words at 4927 wps, loss = 4.224\n",
      "[batch 2390]: seen 2391000 words at 4923 wps, loss = 4.224\n",
      "[batch 2441]: seen 2442000 words at 4925 wps, loss = 4.223\n",
      "[batch 2490]: seen 2491000 words at 4924 wps, loss = 4.222\n",
      "[batch 2540]: seen 2541000 words at 4925 wps, loss = 4.221\n",
      "[batch 2591]: seen 2592000 words at 4928 wps, loss = 4.221\n",
      "[batch 2642]: seen 2643000 words at 4930 wps, loss = 4.220\n",
      "[batch 2690]: seen 2691000 words at 4926 wps, loss = 4.220\n",
      "[batch 2740]: seen 2741000 words at 4927 wps, loss = 4.219\n",
      "[batch 2791]: seen 2792000 words at 4928 wps, loss = 4.219\n",
      "[batch 2842]: seen 2843000 words at 4930 wps, loss = 4.219\n",
      "[batch 2893]: seen 2894000 words at 4931 wps, loss = 4.218\n",
      "[batch 2944]: seen 2945000 words at 4933 wps, loss = 4.217\n",
      "[batch 2995]: seen 2996000 words at 4935 wps, loss = 4.216\n",
      "[batch 3045]: seen 3046000 words at 4936 wps, loss = 4.216\n",
      "[batch 3093]: seen 3094000 words at 4933 wps, loss = 4.216\n",
      "[batch 3144]: seen 3145000 words at 4935 wps, loss = 4.216\n",
      "[batch 3194]: seen 3195000 words at 4935 wps, loss = 4.215\n",
      "[batch 3242]: seen 3243000 words at 4932 wps, loss = 4.215\n",
      "[batch 3293]: seen 3294000 words at 4933 wps, loss = 4.215\n",
      "[batch 3343]: seen 3344000 words at 4934 wps, loss = 4.215\n",
      "[batch 3394]: seen 3395000 words at 4935 wps, loss = 4.214\n",
      "[batch 3445]: seen 3446000 words at 4937 wps, loss = 4.214\n",
      "[batch 3496]: seen 3497000 words at 4938 wps, loss = 4.214\n",
      "[batch 3547]: seen 3548000 words at 4940 wps, loss = 4.214\n",
      "[batch 3597]: seen 3598000 words at 4940 wps, loss = 4.213\n",
      "[batch 3645]: seen 3646000 words at 4938 wps, loss = 4.213\n",
      "[batch 3696]: seen 3697000 words at 4939 wps, loss = 4.212\n",
      "[batch 3747]: seen 3748000 words at 4940 wps, loss = 4.212\n",
      "[batch 3798]: seen 3799000 words at 4941 wps, loss = 4.212\n",
      "[batch 3849]: seen 3850000 words at 4943 wps, loss = 4.211\n",
      "[batch 3900]: seen 3901000 words at 4944 wps, loss = 4.210\n",
      "[batch 3950]: seen 3951000 words at 4944 wps, loss = 4.210\n",
      "[batch 4001]: seen 4002000 words at 4945 wps, loss = 4.209\n",
      "[batch 4052]: seen 4053000 words at 4946 wps, loss = 4.209\n",
      "[batch 4102]: seen 4103000 words at 4947 wps, loss = 4.208\n",
      "[batch 4153]: seen 4154000 words at 4948 wps, loss = 4.207\n",
      "[batch 4204]: seen 4205000 words at 4949 wps, loss = 4.207\n",
      "[batch 4255]: seen 4256000 words at 4950 wps, loss = 4.207\n",
      "[batch 4306]: seen 4307000 words at 4951 wps, loss = 4.206\n",
      "[batch 4357]: seen 4358000 words at 4952 wps, loss = 4.206\n",
      "[batch 4408]: seen 4409000 words at 4953 wps, loss = 4.205\n",
      "[batch 4459]: seen 4460000 words at 4954 wps, loss = 4.205\n",
      "[batch 4510]: seen 4511000 words at 4955 wps, loss = 4.204\n",
      "[batch 4559]: seen 4560000 words at 4954 wps, loss = 4.204\n",
      "[batch 4609]: seen 4610000 words at 4954 wps, loss = 4.204\n",
      "[batch 4659]: seen 4660000 words at 4954 wps, loss = 4.203\n",
      "[batch 4709]: seen 4710000 words at 4954 wps, loss = 4.203\n",
      "[batch 4760]: seen 4761000 words at 4955 wps, loss = 4.202\n",
      "[batch 4811]: seen 4812000 words at 4956 wps, loss = 4.202\n",
      "[batch 4862]: seen 4863000 words at 4957 wps, loss = 4.202\n",
      "[batch 4909]: seen 4910000 words at 4953 wps, loss = 4.202\n",
      "[batch 4958]: seen 4959000 words at 4953 wps, loss = 4.201\n",
      "[batch 5008]: seen 5009000 words at 4953 wps, loss = 4.201\n",
      "[batch 5059]: seen 5060000 words at 4953 wps, loss = 4.200\n",
      "[batch 5110]: seen 5111000 words at 4954 wps, loss = 4.200\n",
      "[batch 5161]: seen 5162000 words at 4955 wps, loss = 4.200\n",
      "[batch 5211]: seen 5212000 words at 4956 wps, loss = 4.199\n",
      "[batch 5262]: seen 5263000 words at 4956 wps, loss = 4.199\n",
      "[batch 5313]: seen 5314000 words at 4957 wps, loss = 4.199\n",
      "[batch 5363]: seen 5364000 words at 4957 wps, loss = 4.199\n",
      "[batch 5414]: seen 5415000 words at 4958 wps, loss = 4.198\n",
      "[batch 5465]: seen 5466000 words at 4959 wps, loss = 4.198\n",
      "[batch 5516]: seen 5517000 words at 4959 wps, loss = 4.198\n",
      "[batch 5567]: seen 5568000 words at 4960 wps, loss = 4.197\n",
      "[batch 5617]: seen 5618000 words at 4961 wps, loss = 4.197\n",
      "[batch 5667]: seen 5668000 words at 4960 wps, loss = 4.196\n",
      "[batch 5716]: seen 5717000 words at 4959 wps, loss = 4.196\n",
      "[batch 5767]: seen 5768000 words at 4960 wps, loss = 4.195\n",
      "[batch 5817]: seen 5818000 words at 4960 wps, loss = 4.195\n",
      "[batch 5868]: seen 5869000 words at 4961 wps, loss = 4.195\n",
      "[batch 5919]: seen 5920000 words at 4961 wps, loss = 4.194\n",
      "[batch 5970]: seen 5971000 words at 4962 wps, loss = 4.194\n",
      "[batch 6021]: seen 6022000 words at 4962 wps, loss = 4.193\n",
      "[batch 6070]: seen 6071000 words at 4961 wps, loss = 4.193\n",
      "[batch 6120]: seen 6121000 words at 4961 wps, loss = 4.192\n",
      "[batch 6171]: seen 6172000 words at 4961 wps, loss = 4.192\n",
      "[batch 6222]: seen 6223000 words at 4962 wps, loss = 4.192\n",
      "[batch 6273]: seen 6274000 words at 4962 wps, loss = 4.191\n",
      "[batch 6324]: seen 6325000 words at 4963 wps, loss = 4.191\n",
      "[batch 6375]: seen 6376000 words at 4963 wps, loss = 4.190\n",
      "[batch 6425]: seen 6426000 words at 4963 wps, loss = 4.190\n",
      "[batch 6475]: seen 6476000 words at 4963 wps, loss = 4.189\n",
      "[batch 6526]: seen 6527000 words at 4963 wps, loss = 4.189\n",
      "[batch 6576]: seen 6577000 words at 4963 wps, loss = 4.189\n",
      "[batch 6626]: seen 6627000 words at 4963 wps, loss = 4.188\n",
      "[batch 6677]: seen 6678000 words at 4964 wps, loss = 4.188\n",
      "[batch 6727]: seen 6728000 words at 4964 wps, loss = 4.187\n",
      "[batch 6778]: seen 6779000 words at 4964 wps, loss = 4.187\n",
      "[batch 6829]: seen 6830000 words at 4965 wps, loss = 4.187\n",
      "[batch 6879]: seen 6880000 words at 4965 wps, loss = 4.186\n",
      "[batch 6930]: seen 6931000 words at 4965 wps, loss = 4.186\n",
      "[batch 6981]: seen 6982000 words at 4966 wps, loss = 4.186\n",
      "[batch 7032]: seen 7033000 words at 4967 wps, loss = 4.185\n",
      "[batch 7083]: seen 7084000 words at 4967 wps, loss = 4.185\n",
      "[batch 7134]: seen 7135000 words at 4967 wps, loss = 4.185\n",
      "[batch 7184]: seen 7185000 words at 4967 wps, loss = 4.184\n",
      "[batch 7235]: seen 7236000 words at 4968 wps, loss = 4.184\n",
      "[batch 7286]: seen 7287000 words at 4968 wps, loss = 4.183\n",
      "[batch 7337]: seen 7338000 words at 4969 wps, loss = 4.183\n",
      "[batch 7387]: seen 7388000 words at 4969 wps, loss = 4.183\n",
      "[batch 7438]: seen 7439000 words at 4969 wps, loss = 4.182\n",
      "[batch 7489]: seen 7490000 words at 4970 wps, loss = 4.182\n",
      "[batch 7540]: seen 7541000 words at 4970 wps, loss = 4.182\n",
      "[batch 7589]: seen 7590000 words at 4969 wps, loss = 4.182\n",
      "[batch 7640]: seen 7641000 words at 4969 wps, loss = 4.182\n",
      "[batch 7690]: seen 7691000 words at 4969 wps, loss = 4.181\n",
      "[batch 7741]: seen 7742000 words at 4970 wps, loss = 4.181\n",
      "[batch 7792]: seen 7793000 words at 4970 wps, loss = 4.181\n",
      "[batch 7841]: seen 7842000 words at 4969 wps, loss = 4.180\n",
      "[batch 7891]: seen 7892000 words at 4969 wps, loss = 4.180\n",
      "[batch 7942]: seen 7943000 words at 4970 wps, loss = 4.180\n",
      "[batch 7992]: seen 7993000 words at 4970 wps, loss = 4.179\n",
      "[batch 8043]: seen 8044000 words at 4970 wps, loss = 4.179\n",
      "[batch 8094]: seen 8095000 words at 4971 wps, loss = 4.178\n",
      "[batch 8145]: seen 8146000 words at 4971 wps, loss = 4.178\n",
      "[batch 8196]: seen 8197000 words at 4971 wps, loss = 4.178\n",
      "[batch 8245]: seen 8246000 words at 4971 wps, loss = 4.177\n",
      "[batch 8294]: seen 8295000 words at 4970 wps, loss = 4.176\n",
      "[batch 8345]: seen 8346000 words at 4971 wps, loss = 4.176\n",
      "[batch 8396]: seen 8397000 words at 4971 wps, loss = 4.176\n",
      "[epoch 2] Completed in 0:28:13\n",
      "[epoch 2] [batch 5]: seen 60000 words at 5415 wps, loss = 3.841\n",
      "[batch 11]: seen 120000 words at 5492 wps, loss = 3.827\n",
      "[batch 17]: seen 180000 words at 5517 wps, loss = 3.822\n",
      "[batch 23]: seen 240000 words at 5515 wps, loss = 3.814\n",
      "[batch 29]: seen 300000 words at 5529 wps, loss = 3.808\n",
      "[batch 35]: seen 360000 words at 5502 wps, loss = 3.803\n",
      "[batch 41]: seen 420000 words at 5513 wps, loss = 3.800\n",
      "Test set: avg. loss: 3.798  (perplexity: 44.60)\n",
      "\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(ranks_corpus, top_training_data, \"top_ranks\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding sentences...\n",
      "Processing sentences...\n",
      "Loaded 414819 sentences (6.58562e+06 tokens)\n",
      "Training set: 394078 sentences (6253483 tokens)\n",
      "Test set: 20741 sentences (332133 tokens)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "bottom_training_data = ranks_corpus.generate_training_data(\n",
    "    ranks_dataset[\"train_data\"][ranks_dataset[\"train_data\"][\"topRank\"] == False][\"content\"],\n",
    "    train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 46]: seen 47000 words at 4667 wps, loss = 7.374\n",
      "[batch 93]: seen 94000 words at 4649 wps, loss = 6.684\n",
      "[batch 145]: seen 146000 words at 4803 wps, loss = 6.410\n",
      "[batch 194]: seen 195000 words at 4818 wps, loss = 6.205\n",
      "[batch 243]: seen 244000 words at 4822 wps, loss = 6.056\n",
      "[batch 295]: seen 296000 words at 4871 wps, loss = 5.936\n",
      "[batch 346]: seen 347000 words at 4896 wps, loss = 5.838\n",
      "[batch 392]: seen 393000 words at 4852 wps, loss = 5.765\n",
      "[batch 443]: seen 444000 words at 4877 wps, loss = 5.705\n",
      "[batch 491]: seen 492000 words at 4869 wps, loss = 5.650\n",
      "[batch 542]: seen 543000 words at 4887 wps, loss = 5.600\n",
      "[batch 592]: seen 593000 words at 4876 wps, loss = 5.555\n",
      "[batch 643]: seen 644000 words at 4889 wps, loss = 5.513\n",
      "[batch 694]: seen 695000 words at 4900 wps, loss = 5.476\n",
      "[batch 743]: seen 744000 words at 4895 wps, loss = 5.443\n",
      "[batch 793]: seen 794000 words at 4898 wps, loss = 5.413\n",
      "[batch 842]: seen 843000 words at 4896 wps, loss = 5.385\n",
      "[batch 893]: seen 894000 words at 4906 wps, loss = 5.359\n",
      "[batch 945]: seen 946000 words at 4917 wps, loss = 5.333\n",
      "[batch 989]: seen 990000 words at 4891 wps, loss = 5.316\n",
      "[batch 1040]: seen 1041000 words at 4898 wps, loss = 5.293\n",
      "[batch 1090]: seen 1091000 words at 4903 wps, loss = 5.274\n",
      "[batch 1140]: seen 1141000 words at 4904 wps, loss = 5.256\n",
      "[batch 1189]: seen 1190000 words at 4902 wps, loss = 5.237\n",
      "[batch 1239]: seen 1240000 words at 4902 wps, loss = 5.219\n",
      "[batch 1288]: seen 1289000 words at 4899 wps, loss = 5.203\n",
      "[batch 1338]: seen 1339000 words at 4901 wps, loss = 5.187\n",
      "[batch 1389]: seen 1390000 words at 4907 wps, loss = 5.173\n",
      "[batch 1440]: seen 1441000 words at 4912 wps, loss = 5.158\n",
      "[batch 1491]: seen 1492000 words at 4915 wps, loss = 5.146\n",
      "[batch 1543]: seen 1544000 words at 4921 wps, loss = 5.132\n",
      "[batch 1594]: seen 1595000 words at 4924 wps, loss = 5.119\n",
      "[batch 1645]: seen 1646000 words at 4915 wps, loss = 5.108\n",
      "[batch 1695]: seen 1696000 words at 4915 wps, loss = 5.096\n",
      "[batch 1743]: seen 1744000 words at 4910 wps, loss = 5.085\n",
      "[batch 1794]: seen 1795000 words at 4913 wps, loss = 5.074\n",
      "[batch 1845]: seen 1846000 words at 4918 wps, loss = 5.065\n",
      "[batch 1896]: seen 1897000 words at 4921 wps, loss = 5.054\n",
      "[batch 1947]: seen 1948000 words at 4925 wps, loss = 5.045\n",
      "[batch 1998]: seen 1999000 words at 4929 wps, loss = 5.035\n",
      "[batch 2049]: seen 2050000 words at 4933 wps, loss = 5.026\n",
      "[batch 2100]: seen 2101000 words at 4936 wps, loss = 5.018\n",
      "[batch 2152]: seen 2153000 words at 4940 wps, loss = 5.008\n",
      "[batch 2204]: seen 2205000 words at 4944 wps, loss = 5.000\n",
      "[batch 2251]: seen 2252000 words at 4937 wps, loss = 4.993\n",
      "[batch 2302]: seen 2303000 words at 4940 wps, loss = 4.984\n",
      "[batch 2351]: seen 2352000 words at 4937 wps, loss = 4.976\n",
      "[batch 2402]: seen 2403000 words at 4940 wps, loss = 4.969\n",
      "[batch 2453]: seen 2454000 words at 4942 wps, loss = 4.961\n",
      "[batch 2504]: seen 2505000 words at 4945 wps, loss = 4.954\n",
      "[batch 2555]: seen 2556000 words at 4947 wps, loss = 4.947\n",
      "[batch 2599]: seen 2600000 words at 4936 wps, loss = 4.941\n",
      "[batch 2647]: seen 2648000 words at 4933 wps, loss = 4.935\n",
      "[batch 2698]: seen 2699000 words at 4935 wps, loss = 4.928\n",
      "[batch 2749]: seen 2750000 words at 4938 wps, loss = 4.921\n",
      "[batch 2801]: seen 2802000 words at 4941 wps, loss = 4.915\n",
      "[batch 2849]: seen 2850000 words at 4937 wps, loss = 4.909\n",
      "[batch 2899]: seen 2900000 words at 4938 wps, loss = 4.904\n",
      "[batch 2948]: seen 2949000 words at 4938 wps, loss = 4.898\n",
      "[batch 2999]: seen 3000000 words at 4939 wps, loss = 4.893\n",
      "[batch 3050]: seen 3051000 words at 4941 wps, loss = 4.887\n",
      "[batch 3102]: seen 3103000 words at 4944 wps, loss = 4.882\n",
      "[batch 3149]: seen 3150000 words at 4940 wps, loss = 4.877\n",
      "[batch 3198]: seen 3199000 words at 4940 wps, loss = 4.872\n",
      "[batch 3249]: seen 3250000 words at 4942 wps, loss = 4.867\n",
      "[batch 3300]: seen 3301000 words at 4943 wps, loss = 4.861\n",
      "[batch 3352]: seen 3353000 words at 4946 wps, loss = 4.856\n",
      "[batch 3403]: seen 3404000 words at 4948 wps, loss = 4.851\n",
      "[batch 3449]: seen 3450000 words at 4942 wps, loss = 4.846\n",
      "[batch 3500]: seen 3501000 words at 4944 wps, loss = 4.842\n",
      "[batch 3546]: seen 3547000 words at 4939 wps, loss = 4.838\n",
      "[batch 3597]: seen 3598000 words at 4940 wps, loss = 4.834\n",
      "[batch 3647]: seen 3648000 words at 4940 wps, loss = 4.829\n",
      "[batch 3698]: seen 3699000 words at 4941 wps, loss = 4.825\n",
      "[batch 3746]: seen 3747000 words at 4936 wps, loss = 4.821\n",
      "[batch 3797]: seen 3798000 words at 4938 wps, loss = 4.817\n",
      "[batch 3849]: seen 3850000 words at 4940 wps, loss = 4.812\n",
      "[batch 3900]: seen 3901000 words at 4941 wps, loss = 4.808\n",
      "[batch 3951]: seen 3952000 words at 4943 wps, loss = 4.804\n",
      "[batch 4001]: seen 4002000 words at 4943 wps, loss = 4.800\n",
      "[batch 4052]: seen 4053000 words at 4944 wps, loss = 4.796\n",
      "[batch 4101]: seen 4102000 words at 4943 wps, loss = 4.792\n",
      "[batch 4153]: seen 4154000 words at 4945 wps, loss = 4.788\n",
      "[batch 4204]: seen 4205000 words at 4946 wps, loss = 4.784\n",
      "[batch 4255]: seen 4256000 words at 4947 wps, loss = 4.780\n",
      "[batch 4306]: seen 4307000 words at 4949 wps, loss = 4.776\n",
      "[batch 4357]: seen 4358000 words at 4950 wps, loss = 4.773\n",
      "[batch 4408]: seen 4409000 words at 4951 wps, loss = 4.769\n",
      "[batch 4460]: seen 4461000 words at 4952 wps, loss = 4.765\n",
      "[batch 4511]: seen 4512000 words at 4954 wps, loss = 4.762\n",
      "[batch 4562]: seen 4563000 words at 4955 wps, loss = 4.759\n",
      "[batch 4612]: seen 4613000 words at 4956 wps, loss = 4.755\n",
      "[batch 4663]: seen 4664000 words at 4956 wps, loss = 4.752\n",
      "[batch 4713]: seen 4714000 words at 4956 wps, loss = 4.749\n",
      "[batch 4764]: seen 4765000 words at 4957 wps, loss = 4.745\n",
      "[batch 4816]: seen 4817000 words at 4959 wps, loss = 4.742\n",
      "[batch 4866]: seen 4867000 words at 4958 wps, loss = 4.739\n",
      "[batch 4917]: seen 4918000 words at 4959 wps, loss = 4.736\n",
      "[batch 4964]: seen 4965000 words at 4956 wps, loss = 4.733\n",
      "[batch 5015]: seen 5016000 words at 4957 wps, loss = 4.729\n",
      "[batch 5067]: seen 5068000 words at 4959 wps, loss = 4.727\n",
      "[batch 5116]: seen 5117000 words at 4958 wps, loss = 4.724\n",
      "[batch 5166]: seen 5167000 words at 4958 wps, loss = 4.721\n",
      "[batch 5218]: seen 5219000 words at 4959 wps, loss = 4.718\n",
      "[batch 5268]: seen 5269000 words at 4959 wps, loss = 4.715\n",
      "[batch 5319]: seen 5320000 words at 4960 wps, loss = 4.712\n",
      "[batch 5371]: seen 5372000 words at 4962 wps, loss = 4.709\n",
      "[batch 5422]: seen 5423000 words at 4962 wps, loss = 4.706\n",
      "[batch 5473]: seen 5474000 words at 4963 wps, loss = 4.704\n",
      "[batch 5523]: seen 5524000 words at 4963 wps, loss = 4.701\n",
      "[batch 5574]: seen 5575000 words at 4964 wps, loss = 4.698\n",
      "[batch 5625]: seen 5626000 words at 4965 wps, loss = 4.696\n",
      "[batch 5675]: seen 5676000 words at 4963 wps, loss = 4.693\n",
      "[batch 5727]: seen 5728000 words at 4964 wps, loss = 4.691\n",
      "[batch 5778]: seen 5779000 words at 4964 wps, loss = 4.688\n",
      "[batch 5827]: seen 5828000 words at 4963 wps, loss = 4.686\n",
      "[batch 5878]: seen 5879000 words at 4965 wps, loss = 4.683\n",
      "[batch 5929]: seen 5930000 words at 4965 wps, loss = 4.681\n",
      "[batch 5978]: seen 5979000 words at 4964 wps, loss = 4.679\n",
      "[batch 6028]: seen 6029000 words at 4964 wps, loss = 4.677\n",
      "[batch 6079]: seen 6080000 words at 4965 wps, loss = 4.674\n",
      "[batch 6128]: seen 6129000 words at 4964 wps, loss = 4.672\n",
      "[batch 6178]: seen 6179000 words at 4964 wps, loss = 4.670\n",
      "[batch 6230]: seen 6231000 words at 4965 wps, loss = 4.667\n",
      "[batch 6277]: seen 6278000 words at 4963 wps, loss = 4.665\n",
      "[batch 6325]: seen 6326000 words at 4961 wps, loss = 4.663\n",
      "[batch 6373]: seen 6374000 words at 4959 wps, loss = 4.661\n",
      "[batch 6424]: seen 6425000 words at 4960 wps, loss = 4.659\n",
      "[batch 6475]: seen 6476000 words at 4961 wps, loss = 4.656\n",
      "[batch 6527]: seen 6528000 words at 4962 wps, loss = 4.654\n",
      "[batch 6578]: seen 6579000 words at 4962 wps, loss = 4.651\n",
      "[batch 6619]: seen 6620000 words at 4955 wps, loss = 4.650\n",
      "[epoch 1] Completed in 0:22:21\n",
      "[epoch 1] [batch 4]: seen 50000 words at 3959 wps, loss = 4.126\n",
      "[batch 10]: seen 110000 words at 4543 wps, loss = 4.116\n",
      "[batch 16]: seen 170000 words at 4806 wps, loss = 4.109\n",
      "[batch 22]: seen 230000 words at 4923 wps, loss = 4.096\n",
      "[batch 28]: seen 290000 words at 5048 wps, loss = 4.082\n",
      "[batch 34]: seen 350000 words at 5107 wps, loss = 4.077\n",
      "Test set: avg. loss: 4.076  (perplexity: 58.93)\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[batch 46]: seen 47000 words at 4627 wps, loss = 4.356\n",
      "[batch 93]: seen 94000 words at 4625 wps, loss = 4.378\n",
      "[batch 143]: seen 144000 words at 4731 wps, loss = 4.384\n",
      "[batch 193]: seen 194000 words at 4796 wps, loss = 4.378\n",
      "[batch 236]: seen 237000 words at 4691 wps, loss = 4.367\n",
      "[batch 285]: seen 286000 words at 4721 wps, loss = 4.366\n",
      "[batch 336]: seen 337000 words at 4762 wps, loss = 4.358\n",
      "[batch 387]: seen 388000 words at 4797 wps, loss = 4.357\n",
      "[batch 437]: seen 438000 words at 4813 wps, loss = 4.359\n",
      "[batch 488]: seen 489000 words at 4840 wps, loss = 4.360\n",
      "[batch 539]: seen 540000 words at 4863 wps, loss = 4.360\n",
      "[batch 589]: seen 590000 words at 4872 wps, loss = 4.358\n",
      "[batch 640]: seen 641000 words at 4888 wps, loss = 4.355\n",
      "[batch 691]: seen 692000 words at 4902 wps, loss = 4.353\n",
      "[batch 742]: seen 743000 words at 4910 wps, loss = 4.350\n",
      "[batch 794]: seen 795000 words at 4922 wps, loss = 4.348\n",
      "[batch 845]: seen 846000 words at 4932 wps, loss = 4.347\n",
      "[batch 895]: seen 896000 words at 4933 wps, loss = 4.346\n",
      "[batch 946]: seen 947000 words at 4941 wps, loss = 4.344\n",
      "[batch 995]: seen 996000 words at 4938 wps, loss = 4.344\n",
      "[batch 1046]: seen 1047000 words at 4942 wps, loss = 4.343\n",
      "[batch 1096]: seen 1097000 words at 4943 wps, loss = 4.342\n",
      "[batch 1146]: seen 1147000 words at 4940 wps, loss = 4.341\n",
      "[batch 1194]: seen 1195000 words at 4932 wps, loss = 4.339\n",
      "[batch 1245]: seen 1246000 words at 4935 wps, loss = 4.338\n",
      "[batch 1292]: seen 1293000 words at 4926 wps, loss = 4.336\n",
      "[batch 1343]: seen 1344000 words at 4931 wps, loss = 4.336\n",
      "[batch 1393]: seen 1394000 words at 4932 wps, loss = 4.337\n",
      "[batch 1443]: seen 1444000 words at 4933 wps, loss = 4.336\n",
      "[batch 1492]: seen 1493000 words at 4930 wps, loss = 4.336\n",
      "[batch 1538]: seen 1539000 words at 4917 wps, loss = 4.334\n",
      "[batch 1589]: seen 1590000 words at 4922 wps, loss = 4.333\n",
      "[batch 1640]: seen 1641000 words at 4926 wps, loss = 4.333\n",
      "[batch 1691]: seen 1692000 words at 4929 wps, loss = 4.332\n",
      "[batch 1741]: seen 1742000 words at 4930 wps, loss = 4.331\n",
      "[batch 1792]: seen 1793000 words at 4934 wps, loss = 4.330\n",
      "[batch 1842]: seen 1843000 words at 4933 wps, loss = 4.330\n",
      "[batch 1893]: seen 1894000 words at 4936 wps, loss = 4.328\n",
      "[batch 1944]: seen 1945000 words at 4940 wps, loss = 4.327\n",
      "[batch 1995]: seen 1996000 words at 4943 wps, loss = 4.327\n",
      "[batch 2041]: seen 2042000 words at 4933 wps, loss = 4.327\n",
      "[batch 2090]: seen 2091000 words at 4927 wps, loss = 4.327\n",
      "[batch 2139]: seen 2140000 words at 4926 wps, loss = 4.325\n",
      "[batch 2190]: seen 2191000 words at 4929 wps, loss = 4.324\n",
      "[batch 2241]: seen 2242000 words at 4932 wps, loss = 4.324\n",
      "[batch 2292]: seen 2293000 words at 4934 wps, loss = 4.323\n",
      "[batch 2343]: seen 2344000 words at 4936 wps, loss = 4.322\n",
      "[batch 2394]: seen 2395000 words at 4939 wps, loss = 4.321\n",
      "[batch 2441]: seen 2442000 words at 4934 wps, loss = 4.320\n",
      "[batch 2491]: seen 2492000 words at 4934 wps, loss = 4.320\n",
      "[batch 2543]: seen 2544000 words at 4937 wps, loss = 4.319\n",
      "[batch 2591]: seen 2592000 words at 4934 wps, loss = 4.318\n",
      "[batch 2642]: seen 2643000 words at 4936 wps, loss = 4.317\n",
      "[batch 2692]: seen 2693000 words at 4935 wps, loss = 4.316\n",
      "[batch 2743]: seen 2744000 words at 4938 wps, loss = 4.315\n",
      "[batch 2793]: seen 2794000 words at 4938 wps, loss = 4.315\n",
      "[batch 2845]: seen 2846000 words at 4941 wps, loss = 4.314\n",
      "[batch 2895]: seen 2896000 words at 4941 wps, loss = 4.314\n",
      "[batch 2944]: seen 2945000 words at 4940 wps, loss = 4.313\n",
      "[batch 2994]: seen 2995000 words at 4940 wps, loss = 4.313\n",
      "[batch 3045]: seen 3046000 words at 4942 wps, loss = 4.312\n",
      "[batch 3096]: seen 3097000 words at 4944 wps, loss = 4.312\n",
      "[batch 3144]: seen 3145000 words at 4941 wps, loss = 4.312\n",
      "[batch 3194]: seen 3195000 words at 4941 wps, loss = 4.310\n",
      "[batch 3243]: seen 3244000 words at 4939 wps, loss = 4.310\n",
      "[batch 3294]: seen 3295000 words at 4942 wps, loss = 4.309\n",
      "[batch 3345]: seen 3346000 words at 4943 wps, loss = 4.308\n",
      "[batch 3396]: seen 3397000 words at 4945 wps, loss = 4.308\n",
      "[batch 3446]: seen 3447000 words at 4944 wps, loss = 4.306\n",
      "[batch 3491]: seen 3492000 words at 4938 wps, loss = 4.306\n",
      "[batch 3538]: seen 3539000 words at 4933 wps, loss = 4.306\n",
      "[batch 3589]: seen 3590000 words at 4935 wps, loss = 4.305\n",
      "[batch 3640]: seen 3641000 words at 4937 wps, loss = 4.304\n",
      "[batch 3689]: seen 3690000 words at 4936 wps, loss = 4.304\n",
      "[batch 3740]: seen 3741000 words at 4939 wps, loss = 4.304\n",
      "[batch 3790]: seen 3791000 words at 4939 wps, loss = 4.303\n",
      "[batch 3841]: seen 3842000 words at 4940 wps, loss = 4.302\n",
      "[batch 3893]: seen 3894000 words at 4942 wps, loss = 4.301\n",
      "[batch 3943]: seen 3944000 words at 4942 wps, loss = 4.301\n",
      "[batch 3994]: seen 3995000 words at 4943 wps, loss = 4.300\n",
      "[batch 4044]: seen 4045000 words at 4944 wps, loss = 4.300\n",
      "[batch 4089]: seen 4090000 words at 4939 wps, loss = 4.299\n",
      "[batch 4140]: seen 4141000 words at 4939 wps, loss = 4.298\n",
      "[batch 4189]: seen 4190000 words at 4939 wps, loss = 4.298\n",
      "[batch 4240]: seen 4241000 words at 4940 wps, loss = 4.297\n",
      "[batch 4288]: seen 4289000 words at 4938 wps, loss = 4.296\n",
      "[batch 4339]: seen 4340000 words at 4939 wps, loss = 4.296\n",
      "[batch 4391]: seen 4392000 words at 4941 wps, loss = 4.295\n",
      "[batch 4441]: seen 4442000 words at 4942 wps, loss = 4.295\n",
      "[batch 4492]: seen 4493000 words at 4943 wps, loss = 4.294\n",
      "[batch 4544]: seen 4545000 words at 4945 wps, loss = 4.293\n",
      "[batch 4594]: seen 4595000 words at 4945 wps, loss = 4.293\n",
      "[batch 4645]: seen 4646000 words at 4946 wps, loss = 4.292\n",
      "[batch 4696]: seen 4697000 words at 4948 wps, loss = 4.291\n",
      "[batch 4743]: seen 4744000 words at 4945 wps, loss = 4.291\n",
      "[batch 4794]: seen 4795000 words at 4946 wps, loss = 4.290\n",
      "[batch 4846]: seen 4847000 words at 4947 wps, loss = 4.289\n",
      "[batch 4896]: seen 4897000 words at 4947 wps, loss = 4.289\n",
      "[batch 4947]: seen 4948000 words at 4948 wps, loss = 4.288\n",
      "[batch 4998]: seen 4999000 words at 4949 wps, loss = 4.287\n",
      "[batch 5049]: seen 5050000 words at 4950 wps, loss = 4.287\n",
      "[batch 5100]: seen 5101000 words at 4952 wps, loss = 4.287\n",
      "[batch 5151]: seen 5152000 words at 4953 wps, loss = 4.286\n",
      "[batch 5202]: seen 5203000 words at 4954 wps, loss = 4.286\n",
      "[batch 5252]: seen 5253000 words at 4954 wps, loss = 4.285\n",
      "[batch 5303]: seen 5304000 words at 4955 wps, loss = 4.285\n",
      "[batch 5354]: seen 5355000 words at 4956 wps, loss = 4.284\n",
      "[batch 5401]: seen 5402000 words at 4953 wps, loss = 4.284\n",
      "[batch 5451]: seen 5452000 words at 4954 wps, loss = 4.284\n",
      "[batch 5502]: seen 5503000 words at 4954 wps, loss = 4.283\n",
      "[batch 5553]: seen 5554000 words at 4955 wps, loss = 4.282\n",
      "[batch 5604]: seen 5605000 words at 4956 wps, loss = 4.282\n",
      "[batch 5652]: seen 5653000 words at 4954 wps, loss = 4.281\n",
      "[batch 5703]: seen 5704000 words at 4954 wps, loss = 4.281\n",
      "[batch 5754]: seen 5755000 words at 4955 wps, loss = 4.281\n",
      "[batch 5804]: seen 5805000 words at 4955 wps, loss = 4.280\n",
      "[batch 5855]: seen 5856000 words at 4956 wps, loss = 4.280\n",
      "[batch 5905]: seen 5906000 words at 4956 wps, loss = 4.280\n",
      "[batch 5956]: seen 5957000 words at 4957 wps, loss = 4.279\n",
      "[batch 6006]: seen 6007000 words at 4957 wps, loss = 4.279\n",
      "[batch 6057]: seen 6058000 words at 4958 wps, loss = 4.279\n",
      "[batch 6108]: seen 6109000 words at 4958 wps, loss = 4.278\n",
      "[batch 6158]: seen 6159000 words at 4958 wps, loss = 4.277\n",
      "[batch 6208]: seen 6209000 words at 4958 wps, loss = 4.277\n",
      "[batch 6259]: seen 6260000 words at 4959 wps, loss = 4.276\n",
      "[batch 6308]: seen 6309000 words at 4958 wps, loss = 4.276\n",
      "[batch 6359]: seen 6360000 words at 4959 wps, loss = 4.275\n",
      "[batch 6409]: seen 6410000 words at 4959 wps, loss = 4.275\n",
      "[batch 6456]: seen 6457000 words at 4957 wps, loss = 4.274\n",
      "[batch 6507]: seen 6508000 words at 4958 wps, loss = 4.273\n",
      "[batch 6558]: seen 6559000 words at 4959 wps, loss = 4.273\n",
      "[batch 6608]: seen 6609000 words at 4959 wps, loss = 4.272\n",
      "[epoch 2] Completed in 0:22:20\n",
      "[epoch 2] [batch 5]: seen 60000 words at 5357 wps, loss = 3.915\n",
      "[batch 11]: seen 120000 words at 5487 wps, loss = 3.923\n",
      "[batch 17]: seen 180000 words at 5547 wps, loss = 3.914\n",
      "[batch 23]: seen 240000 words at 5570 wps, loss = 3.905\n",
      "[batch 29]: seen 300000 words at 5581 wps, loss = 3.897\n",
      "Test set: avg. loss: 3.894  (perplexity: 49.10)\n",
      "\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "train_model(ranks_corpus, bottom_training_data, \"bottom_ranks\", model_params, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for TRUE model:\n",
      "\"the quick brown fox jumps over the lazy dog\" : -73.35\n",
      "\"the fox quick brown jumps over the lazy dog\" : -75.83\n",
      "\"the fox quick brown jumps dog over the lazy\" : -79.17\n",
      "Scores for FALSE model:\n",
      "\"the quick brown fox jumps over the lazy dog\" : -74.41\n",
      "\"the fox quick brown jumps over the lazy dog\" : -76.30\n",
      "\"the fox quick brown jumps dog over the lazy\" : -77.44\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "sents = [\"the quick brown fox jumps over the lazy dog\",\n",
    "         \"the fox quick brown jumps over the lazy dog\",\n",
    "        \"the fox quick brown jumps dog over the lazy\"]\n",
    "print \"Scores for TRUE model:\"\n",
    "rnnlm.load_and_score([s.split() for s in sents], ranks_corpus, model_params, \"tf_saved/rnnlm_top_ranks\")\n",
    "print \"Scores for FALSE model:\"\n",
    "rnnlm.load_and_score([s.split() for s in sents], ranks_corpus, model_params, \"tf_saved/rnnlm_bottom_ranks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ka-rank-balanced dataset.\n",
      "Training feature extractor ranks-rnn.\n",
      "True scores...\n",
      "  0 / 10178 (54.553959)\n",
      "  100 / 10178 (202.424813)\n",
      "  200 / 10178 (542.022327)\n",
      "  300 / 10178 (531.714519)\n",
      "  400 / 10178 (96.577904)\n",
      "  500 / 10178 (46.527985)\n",
      "  600 / 10178 (64.722961)\n",
      "  700 / 10178 (301.493820)\n",
      "  800 / 10178 (220.761566)\n",
      "  900 / 10178 (21.050035)\n",
      "  1000 / 10178 (134.259415)\n",
      "  1100 / 10178 (116.186839)\n",
      "  1200 / 10178 (456.439852)\n",
      "  1300 / 10178 (103.805710)\n",
      "  1400 / 10178 (525.499256)\n",
      "  1500 / 10178 (476.682327)\n",
      "  1600 / 10178 (171.589852)\n",
      "  1700 / 10178 (51.491280)\n",
      "  1800 / 10178 (120.448235)\n",
      "  1900 / 10178 (14.712406)\n",
      "  2000 / 10178 (103.330330)\n",
      "  2100 / 10178 (62.872917)\n",
      "  2200 / 10178 (91.369926)\n",
      "  2300 / 10178 (307.247263)\n",
      "  2400 / 10178 (66.381248)\n",
      "  2500 / 10178 (340.174171)\n",
      "  2600 / 10178 (37.261574)\n",
      "  2700 / 10178 (344.294365)\n",
      "  2800 / 10178 (421.615618)\n",
      "  2900 / 10178 (482.847153)\n",
      "  3000 / 10178 (19.225313)\n",
      "  3100 / 10178 (549.985173)\n",
      "  3200 / 10178 (65.415085)\n",
      "  3300 / 10178 (394.069366)\n",
      "  3400 / 10178 (19.038082)\n",
      "  3500 / 10178 (80.091537)\n",
      "  3600 / 10178 (155.961563)\n",
      "  3700 / 10178 (30.307879)\n",
      "  3800 / 10178 (497.663521)\n",
      "  3900 / 10178 (531.986084)\n",
      "  4000 / 10178 (309.712036)\n",
      "  4100 / 10178 (94.453238)\n",
      "  4200 / 10178 (208.506638)\n",
      "  4300 / 10178 (32.555946)\n",
      "  4400 / 10178 (155.016399)\n",
      "  4500 / 10178 (117.958801)\n",
      "  4600 / 10178 (90.618729)\n",
      "  4700 / 10178 (75.462509)\n",
      "  4800 / 10178 (161.531021)\n",
      "  4900 / 10178 (629.633976)\n",
      "  5000 / 10178 (28.698200)\n",
      "  5100 / 10178 (26.029926)\n",
      "  5200 / 10178 (77.465744)\n",
      "  5300 / 10178 (6.660340)\n",
      "  5400 / 10178 (24.939734)\n",
      "  5500 / 10178 (597.485981)\n",
      "  5600 / 10178 (47.982277)\n",
      "  5700 / 10178 (543.756042)\n",
      "  5800 / 10178 (264.021259)\n",
      "  5900 / 10178 (483.027786)\n",
      "  6000 / 10178 (497.816780)\n",
      "  6100 / 10178 (267.808369)\n",
      "  6200 / 10178 (181.951897)\n",
      "  6300 / 10178 (78.794464)\n",
      "  6400 / 10178 (449.138588)\n",
      "  6500 / 10178 (101.450054)\n",
      "  6600 / 10178 (172.687839)\n",
      "  6700 / 10178 (76.060921)\n",
      "  6800 / 10178 (289.044178)\n",
      "  6900 / 10178 (66.427509)\n",
      "  7000 / 10178 (120.070177)\n",
      "  7100 / 10178 (83.693859)\n",
      "  7200 / 10178 (31.602648)\n",
      "  7300 / 10178 (60.835587)\n",
      "  7400 / 10178 (57.771194)\n",
      "  7500 / 10178 (295.786758)\n",
      "  7600 / 10178 (220.016514)\n",
      "  7700 / 10178 (368.601112)\n",
      "  7800 / 10178 (203.394806)\n",
      "  7900 / 10178 (26.362574)\n",
      "  8000 / 10178 (50.397061)\n",
      "  8100 / 10178 (161.456680)\n",
      "  8200 / 10178 (115.596497)\n",
      "  8300 / 10178 (58.885414)\n",
      "  8400 / 10178 (17.789967)\n",
      "  8500 / 10178 (207.180912)\n",
      "  8600 / 10178 (403.253623)\n",
      "  8700 / 10178 (20.190853)\n",
      "  8800 / 10178 (505.984573)\n",
      "  8900 / 10178 (259.383354)\n",
      "  9000 / 10178 (371.699478)\n",
      "  9100 / 10178 (280.113876)\n",
      "  9200 / 10178 (446.707687)\n",
      "  9300 / 10178 (605.821392)\n",
      "  9400 / 10178 (68.485535)\n",
      "  9500 / 10178 (94.312154)\n",
      "  9600 / 10178 (120.536476)\n",
      "  9700 / 10178 (68.003197)\n",
      "  9800 / 10178 (82.850616)\n",
      "  9900 / 10178 (56.570129)\n",
      "  10000 / 10178 (331.965157)\n",
      "  10100 / 10178 (36.587814)\n",
      "False scores...\n",
      "  0 / 10178 (54.127357)\n",
      "  100 / 10178 (203.320450)\n",
      "  200 / 10178 (562.629158)\n",
      "  300 / 10178 (559.738239)\n",
      "  400 / 10178 (95.673599)\n",
      "  500 / 10178 (44.881283)\n",
      "  600 / 10178 (66.063705)\n",
      "  700 / 10178 (305.551865)\n",
      "  800 / 10178 (220.777512)\n",
      "  900 / 10178 (22.760092)\n",
      "  1000 / 10178 (135.825241)\n",
      "  1100 / 10178 (118.433149)\n",
      "  1200 / 10178 (472.148466)\n",
      "  1300 / 10178 (108.348900)\n",
      "  1400 / 10178 (536.401016)\n",
      "  1500 / 10178 (478.818802)\n",
      "  1600 / 10178 (179.533404)\n",
      "  1700 / 10178 (52.125961)\n",
      "  1800 / 10178 (118.681816)\n",
      "  1900 / 10178 (13.516798)\n",
      "  2000 / 10178 (93.644919)\n",
      "  2100 / 10178 (63.576210)\n",
      "  2200 / 10178 (87.729477)\n",
      "  2300 / 10178 (309.307292)\n",
      "  2400 / 10178 (70.133255)\n",
      "  2500 / 10178 (347.466194)\n",
      "  2600 / 10178 (38.064030)\n",
      "  2700 / 10178 (342.813538)\n",
      "  2800 / 10178 (441.591747)\n",
      "  2900 / 10178 (490.899628)\n",
      "  3000 / 10178 (17.911949)\n",
      "  3100 / 10178 (549.814611)\n",
      "  3200 / 10178 (63.537823)\n",
      "  3300 / 10178 (404.619141)\n",
      "  3400 / 10178 (18.913973)\n",
      "  3500 / 10178 (84.757034)\n",
      "  3600 / 10178 (157.885254)\n",
      "  3700 / 10178 (31.038158)\n",
      "  3800 / 10178 (505.530592)\n",
      "  3900 / 10178 (551.913441)\n",
      "  4000 / 10178 (296.518883)\n",
      "  4100 / 10178 (94.082685)\n",
      "  4200 / 10178 (219.607075)\n",
      "  4300 / 10178 (32.324661)\n",
      "  4400 / 10178 (162.597652)\n",
      "  4500 / 10178 (124.962746)\n",
      "  4600 / 10178 (93.210526)\n",
      "  4700 / 10178 (72.053848)\n",
      "  4800 / 10178 (170.916069)\n",
      "  4900 / 10178 (638.294079)\n",
      "  5000 / 10178 (31.984467)\n",
      "  5100 / 10178 (22.655470)\n",
      "  5200 / 10178 (76.719315)\n",
      "  5300 / 10178 (5.881289)\n",
      "  5400 / 10178 (28.249096)\n",
      "  5500 / 10178 (605.134104)\n",
      "  5600 / 10178 (46.133041)\n",
      "  5700 / 10178 (549.592407)\n",
      "  5800 / 10178 (266.663502)\n",
      "  5900 / 10178 (478.952179)\n",
      "  6000 / 10178 (509.620552)\n",
      "  6100 / 10178 (275.989506)\n",
      "  6200 / 10178 (182.874207)\n",
      "  6300 / 10178 (78.186180)\n",
      "  6400 / 10178 (438.169098)\n",
      "  6500 / 10178 (104.413897)\n",
      "  6600 / 10178 (170.871748)\n",
      "  6700 / 10178 (80.056641)\n",
      "  6800 / 10178 (276.832575)\n",
      "  6900 / 10178 (66.318150)\n",
      "  7000 / 10178 (131.517982)\n",
      "  7100 / 10178 (86.078941)\n",
      "  7200 / 10178 (31.712879)\n",
      "  7300 / 10178 (57.566677)\n",
      "  7400 / 10178 (54.887829)\n",
      "  7500 / 10178 (303.114410)\n",
      "  7600 / 10178 (235.073715)\n",
      "  7700 / 10178 (378.036064)\n",
      "  7800 / 10178 (201.890259)\n",
      "  7900 / 10178 (27.617746)\n",
      "  8000 / 10178 (50.742805)\n",
      "  8100 / 10178 (160.813171)\n",
      "  8200 / 10178 (117.613899)\n",
      "  8300 / 10178 (58.316261)\n",
      "  8400 / 10178 (16.884674)\n",
      "  8500 / 10178 (203.343529)\n",
      "  8600 / 10178 (418.669494)\n",
      "  8700 / 10178 (17.130016)\n",
      "  8800 / 10178 (530.877090)\n",
      "  8900 / 10178 (281.755417)\n",
      "  9000 / 10178 (373.136490)\n",
      "  9100 / 10178 (275.112186)\n",
      "  9200 / 10178 (438.840469)\n",
      "  9300 / 10178 (607.521488)\n",
      "  9400 / 10178 (73.147141)\n",
      "  9500 / 10178 (97.600768)\n",
      "  9600 / 10178 (121.543182)\n",
      "  9700 / 10178 (66.198677)\n",
      "  9800 / 10178 (86.890472)\n",
      "  9900 / 10178 (58.268906)\n",
      "  10000 / 10178 (340.647743)\n",
      "  10100 / 10178 (37.247208)\n",
      "Generating validation set...\n",
      "True scores...\n",
      "  0 / 5000 (88.942566)\n",
      "  100 / 5000 (39.883209)\n",
      "  200 / 5000 (64.204987)\n",
      "  300 / 5000 (40.374115)\n",
      "  400 / 5000 (62.462515)\n",
      "  500 / 5000 (217.498199)\n",
      "  600 / 5000 (227.263393)\n",
      "  700 / 5000 (187.117096)\n",
      "  800 / 5000 (30.609627)\n",
      "  900 / 5000 (51.334381)\n",
      "  1000 / 5000 (16.036434)\n",
      "  1100 / 5000 (147.893764)\n",
      "  1200 / 5000 (92.388237)\n",
      "  1300 / 5000 (29.452633)\n",
      "  1400 / 5000 (88.512314)\n",
      "  1500 / 5000 (97.939987)\n",
      "  1600 / 5000 (62.617188)\n",
      "  1700 / 5000 (262.647224)\n",
      "  1800 / 5000 (56.058426)\n",
      "  1900 / 5000 (300.462868)\n",
      "  2000 / 5000 (55.443302)\n",
      "  2100 / 5000 (57.499794)\n",
      "  2200 / 5000 (65.881790)\n",
      "  2300 / 5000 (21.894699)\n",
      "  2400 / 5000 (77.487793)\n",
      "  2500 / 5000 (46.874077)\n",
      "  2600 / 5000 (104.812309)\n",
      "  2700 / 5000 (31.190380)\n",
      "  2800 / 5000 (183.837975)\n",
      "  2900 / 5000 (31.325233)\n",
      "  3000 / 5000 (40.882008)\n",
      "  3100 / 5000 (47.458176)\n",
      "  3200 / 5000 (174.603171)\n",
      "  3300 / 5000 (28.042421)\n",
      "  3400 / 5000 (60.622353)\n",
      "  3500 / 5000 (184.590363)\n",
      "  3600 / 5000 (214.908127)\n",
      "  3700 / 5000 (170.611450)\n",
      "  3800 / 5000 (303.752327)\n",
      "  3900 / 5000 (54.074863)\n",
      "  4000 / 5000 (16.392761)\n",
      "  4100 / 5000 (54.814949)\n",
      "  4200 / 5000 (89.587975)\n",
      "  4300 / 5000 (39.158916)\n",
      "  4400 / 5000 (57.015001)\n",
      "  4500 / 5000 (63.476918)\n",
      "  4600 / 5000 (14.047434)\n",
      "  4700 / 5000 (18.466045)\n",
      "  4800 / 5000 (67.708687)\n",
      "  4900 / 5000 (54.984333)\n",
      "False scores...\n",
      "  0 / 5000 (87.556999)\n",
      "  100 / 5000 (40.506279)\n",
      "  200 / 5000 (66.650561)\n",
      "  300 / 5000 (40.380730)\n",
      "  400 / 5000 (56.862282)\n",
      "  500 / 5000 (220.007980)\n",
      "  600 / 5000 (234.824669)\n",
      "  700 / 5000 (198.766167)\n",
      "  800 / 5000 (32.878960)\n",
      "  900 / 5000 (55.745823)\n",
      "  1000 / 5000 (15.872431)\n",
      "  1100 / 5000 (125.883425)\n",
      "  1200 / 5000 (93.199348)\n",
      "  1300 / 5000 (30.435333)\n",
      "  1400 / 5000 (88.763252)\n",
      "  1500 / 5000 (99.473190)\n",
      "  1600 / 5000 (65.364273)\n",
      "  1700 / 5000 (269.204842)\n",
      "  1800 / 5000 (56.450176)\n",
      "  1900 / 5000 (307.392979)\n",
      "  2000 / 5000 (57.551834)\n",
      "  2100 / 5000 (58.727295)\n",
      "  2200 / 5000 (65.417221)\n",
      "  2300 / 5000 (22.491205)\n",
      "  2400 / 5000 (74.058014)\n",
      "  2500 / 5000 (46.214081)\n",
      "  2600 / 5000 (97.407494)\n",
      "  2700 / 5000 (30.483118)\n",
      "  2800 / 5000 (185.726692)\n",
      "  2900 / 5000 (33.934769)\n",
      "  3000 / 5000 (39.590038)\n",
      "  3100 / 5000 (44.518005)\n",
      "  3200 / 5000 (176.052139)\n",
      "  3300 / 5000 (27.348759)\n",
      "  3400 / 5000 (61.396500)\n",
      "  3500 / 5000 (190.557655)\n",
      "  3600 / 5000 (205.208740)\n",
      "  3700 / 5000 (158.894367)\n",
      "  3800 / 5000 (310.861946)\n",
      "  3900 / 5000 (52.600315)\n",
      "  4000 / 5000 (15.377506)\n",
      "  4100 / 5000 (51.405396)\n",
      "  4200 / 5000 (90.519272)\n",
      "  4300 / 5000 (39.384411)\n",
      "  4400 / 5000 (55.296535)\n",
      "  4500 / 5000 (61.555982)\n",
      "  4600 / 5000 (13.481023)\n",
      "  4700 / 5000 (16.387600)\n",
      "  4800 / 5000 (65.663033)\n",
      "  4900 / 5000 (54.855473)\n",
      "Generating test set...\n",
      "True scores...\n",
      "  0 / 5000 (16.309677)\n",
      "  100 / 5000 (86.714157)\n",
      "  200 / 5000 (61.512169)\n",
      "  300 / 5000 (449.210854)\n",
      "  400 / 5000 (58.851600)\n",
      "  500 / 5000 (438.180252)\n",
      "  600 / 5000 (58.023357)\n",
      "  700 / 5000 (75.876617)\n",
      "  800 / 5000 (214.064276)\n",
      "  900 / 5000 (61.886238)\n",
      "  1000 / 5000 (19.501898)\n",
      "  1100 / 5000 (46.050476)\n",
      "  1200 / 5000 (78.112362)\n",
      "  1300 / 5000 (75.910460)\n",
      "  1400 / 5000 (36.877655)\n",
      "  1500 / 5000 (18.218124)\n",
      "  1600 / 5000 (22.503881)\n",
      "  1700 / 5000 (11.595560)\n",
      "  1800 / 5000 (141.700808)\n",
      "  1900 / 5000 (37.364529)\n",
      "  2000 / 5000 (155.253422)\n",
      "  2100 / 5000 (4.448112)\n",
      "  2200 / 5000 (8.335903)\n",
      "  2300 / 5000 (54.658321)\n",
      "  2400 / 5000 (40.339649)\n",
      "  2500 / 5000 (33.233498)\n",
      "  2600 / 5000 (68.077965)\n",
      "  2700 / 5000 (19.332054)\n",
      "  2800 / 5000 (15.663475)\n",
      "  2900 / 5000 (140.256468)\n",
      "  3000 / 5000 (238.610401)\n",
      "  3100 / 5000 (30.744205)\n",
      "  3200 / 5000 (63.583458)\n",
      "  3300 / 5000 (487.803242)\n",
      "  3400 / 5000 (78.181107)\n",
      "  3500 / 5000 (63.664581)\n",
      "  3600 / 5000 (31.903004)\n",
      "  3700 / 5000 (177.690716)\n",
      "  3800 / 5000 (9.374296)\n",
      "  3900 / 5000 (538.728611)\n",
      "  4000 / 5000 (102.699112)\n",
      "  4100 / 5000 (16.545563)\n",
      "  4200 / 5000 (98.559220)\n",
      "  4300 / 5000 (58.189220)\n",
      "  4400 / 5000 (250.589821)\n",
      "  4500 / 5000 (32.407150)\n",
      "  4600 / 5000 (33.033386)\n",
      "  4700 / 5000 (4.448112)\n",
      "  4800 / 5000 (37.271317)\n",
      "  4900 / 5000 (331.542122)\n",
      "False scores...\n",
      "  0 / 5000 (18.038269)\n",
      "  100 / 5000 (86.525879)\n",
      "  200 / 5000 (59.171627)\n",
      "  300 / 5000 (464.792198)\n",
      "  400 / 5000 (58.210636)\n",
      "  500 / 5000 (462.544327)\n",
      "  600 / 5000 (58.305988)\n",
      "  700 / 5000 (79.072792)\n",
      "  800 / 5000 (215.745462)\n",
      "  900 / 5000 (63.564285)\n",
      "  1000 / 5000 (18.739735)\n",
      "  1100 / 5000 (44.811966)\n",
      "  1200 / 5000 (79.201187)\n",
      "  1300 / 5000 (78.161262)\n",
      "  1400 / 5000 (36.835365)\n",
      "  1500 / 5000 (18.090347)\n",
      "  1600 / 5000 (21.903900)\n",
      "  1700 / 5000 (12.079765)\n",
      "  1800 / 5000 (146.162624)\n",
      "  1900 / 5000 (36.882008)\n",
      "  2000 / 5000 (151.953093)\n",
      "  2100 / 5000 (4.552845)\n",
      "  2200 / 5000 (8.594584)\n",
      "  2300 / 5000 (53.770386)\n",
      "  2400 / 5000 (43.749542)\n",
      "  2500 / 5000 (33.601288)\n",
      "  2600 / 5000 (65.786774)\n",
      "  2700 / 5000 (18.859547)\n",
      "  2800 / 5000 (14.893226)\n",
      "  2900 / 5000 (145.118687)\n",
      "  3000 / 5000 (243.799164)\n",
      "  3100 / 5000 (31.999395)\n",
      "  3200 / 5000 (63.125576)\n",
      "  3300 / 5000 (545.512619)\n",
      "  3400 / 5000 (80.101784)\n",
      "  3500 / 5000 (69.727448)\n",
      "  3600 / 5000 (32.229904)\n",
      "  3700 / 5000 (172.557705)\n",
      "  3800 / 5000 (7.900073)\n",
      "  3900 / 5000 (581.234562)\n",
      "  4000 / 5000 (96.277321)\n",
      "  4100 / 5000 (14.559194)\n",
      "  4200 / 5000 (100.946358)\n",
      "  4300 / 5000 (53.848492)\n",
      "  4400 / 5000 (247.371129)\n",
      "  4500 / 5000 (34.525097)\n",
      "  4600 / 5000 (33.369373)\n",
      "  4700 / 5000 (4.552845)\n",
      "  4800 / 5000 (39.973885)\n",
      "  4900 / 5000 (326.577812)\n",
      "Writing to disk...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(processing)\n",
    "reload(common)\n",
    "common.extract_features(\n",
    "    \"ka-rank-balanced\",\n",
    "    RNNClassifierFeatureExtractor(ranks_corpus, model_params, \"top_ranks\", \"bottom_ranks\"),\n",
    "    \"ranks-rnn\", sampling=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features ranks-rnn.\n",
      "Training models.\n",
      "##        MultinomialNB       ranks-rnn precision: 49.5% recall: 25.4%\n",
      "##            LinearSVC       ranks-rnn precision: 49.2% recall: 89.6%\n",
      "##                  MLP       ranks-rnn precision: 48.0% recall: 30.6%\n",
      "##                 MLP2       ranks-rnn precision: 47.4% recall: 27.1%\n"
     ]
    }
   ],
   "source": [
    "reload(common)\n",
    "common.test_features(\"ranks-rnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

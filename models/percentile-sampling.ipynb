{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: refactor to use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readSampleData():\n",
    "    # A sample of the data is stored in a single file in sampleData/part-00000\n",
    "    # from the previous step (MRJob_RandomSample.py)\n",
    "    sampleData = []  \n",
    "\n",
    "    with open(\"sampleData/part-00000\",\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            avg,lisst = line.split(\"\\t\")\n",
    "            sampleData.append(float(avg))\n",
    "            \n",
    "    return sampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array, percentile, linspace, random\n",
    "\n",
    "def partition(data, num_of_partitions=10, return_percentiles=False):\n",
    "    # remove percentile 100\n",
    "    qs = linspace(0, 100, num=num_of_partitions, endpoint=False)\n",
    "    if not return_percentiles:\n",
    "        return percentile(data, qs)\n",
    "    return percentile(data, qs), qs\n",
    "\n",
    "sampleData = readSampleData()\n",
    "\n",
    "# (partitionFile, percentiles)\n",
    "partition(sampleData, 4, return_percentiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw implementation w/o using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MAKE % BASED BUCKETS FROM SAMPLE DATA\n",
    "# We can ignore this block. better to use the numpy implementation above.\n",
    "from __future__ import division\n",
    "from math import ceil\n",
    "\n",
    "sampleData = readSampleData()\n",
    "\n",
    "num_buckets = 4 # This will be the number of reducers\n",
    "len_data = len(sampleData)\n",
    "\n",
    "# make breakpoints:\n",
    "partitionFile = []\n",
    "\n",
    "i = 0\n",
    "while i < len_data:\n",
    "    partitionFile.append(sampleData[i])\n",
    "    i += int(ceil(len_data/num_buckets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualizae Partition File\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "fig, ax = pl.subplots(figsize=(10,6))\n",
    "\n",
    "ax.hist(sampleData,color=\"#48afe0\",edgecolor='none')\n",
    "\n",
    "xcoords = partitionFile\n",
    "for xc in xcoords:\n",
    "    pl.axvline(x=xc,color=\"#197f74\", linewidth=1)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "pl.title(\"Parition file for \"+str(num_buckets)+\" buckets\")\n",
    "pl.show()\n",
    "\n",
    "print \"Sample Data min\", min(sampleData)\n",
    "print \"Sample Data max\", max(sampleData)\n",
    "print partitionFile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
